---
title: "Project 02 Hints"
author: "Finn Lindgren"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: |
  %\VignetteIndexEntry{Project 02 Hints}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png",
  dev.args = list(type = "cairo-png"),
  fig.width = 6
)
set.seed(12345L)
```

# Extracting information from linear model objects

When we've estimated a linear model with `lm()`, we often want to extract information
to be used in presentation of results (tables and figures) or in further calculations.
You've already used the `predict()` function for calculating predictions and
prediction uncertainties. In Project 2, you also need to access information
about the estimated parameters and their uncertainty.

Let's say we've estimated a simple model:
```{r}
fit <- lm(y ~ 1 + x, data = data.frame(x = rnorm(10), y = rnorm(10)))
```

## Basic option

The coefficient estimates can be extracted with
```{r}
coef(fit)
coef(fit)["x"]
```

The estimated covariance matrix of the coefficient estimates can be extracted with
```{r}
vcov(fit)
```
To get Standard Error for a coefficient, extract the diagonal element and take
the square root.
```{r}
sqrt(vcov(fit)["x", "x"])
```

The coefficient information can be combined with standard errors to construct approximate
confidence intervals, which in the project can be plotted with `geom_ribbon()`.

The coefficient estimates and uncertainty information can also be extracted with
```{r}
summary(fit)$coefficients
```
To extract specific elements:
```{r}
coefs <- summary(fit)$coefficients
coefs["x", "Estimate"]
coefs["x", "Std. Error"]
```

## Tidy option

The `broom` package can provide the same information in a similar way, but for
this particular type of problem it doesn't really add any value over the basic
approach:
```{r}
suppressPackageStartupMessages(library(tidyverse))
library(broom)
tidy(fit)
tidy(fit) %>%
  filter(term == "x") %>%
  pull(std.error)
```

## Prediction variances

The `predict()` function can provide prediction standard errors, with `se.fit`, but those are only half the story when predicting new data. The standard errors only include the uncertainty information about the linear predictor curve. For full prediction uncertainty,
we need to take the observation variation into account, which `lm()` estimated
via the variance of the residuals. Since the residuals for new observations is assumed to be conditionally independent of the predictor curve, the prediction variance
can be estimated as the
sum of the square of the prediction standard error and the residual variance,
if the degrees of freedom is large.
For the help text for `lm()` we see that when `se.fit=TRUE`, the output list
contains the elements

* `fit`: vector or matrix (depending on the `interval` argument)
* `se.fit`: standard error of predicted means
* `residual.scale`: residual standard deviations
* `df`: degrees of freedom for residual


```{r}
df <- tibble(x = rnorm(10), y = 2 + x + rnorm(10, sd = 0.1))
fit <- lm(y ~ x, data = df)
df_pred <- data.frame(x = seq(-2, 2, length.out = 100))
pred <- predict(fit, newdata = df_pred, se.fit = TRUE)
sd_pred <- sqrt(pred$se.fit^2 + pred$residual.scale^2)
ggplot(cbind(df_pred, se.fit = pred$se.fit, sd_pred = sd_pred)) +
  geom_line(aes(x, se.fit, colour = "se.fit")) +
  geom_line(aes(x, sd_pred, colour = "sd_pred")) +
  ylab("Std. deviations")
```

We can check our logic by comparing our own prediction interval construction to that obstained with `interval="prediction"`:
```{r}
pred <- predict(fit, newdata = df_pred, se.fit = TRUE, interval = "prediction")
sd_pred <- sqrt(pred$se.fit^2 + pred$residual.scale^2)
ggplot(cbind(df_pred,
             as.data.frame(pred$fit),
             se.fit = pred$se.fit,
             sd_pred = sd_pred)) +
  geom_line(aes(x, fit)) +
  geom_ribbon(aes(x,
                  ymin = fit - qnorm(0.975) * sd_pred,
                  ymax = fit - qnorm(0.025) * sd_pred,
                  fill = "our method"), alpha = 0.2) +
  geom_ribbon(aes(x,
                  ymin = lwr,
                  ymax = upr,
                  fill = "predict"), alpha = 0.2)
```

There is a small difference between the two methods, which is explained by the
relatively small degrees of freedom, `r pred$df`, as seen from the matching
ratios for the $t$- and Normal quantiles, and for the interval widths
```{r}
c(qt(0.975, df = pred$df) / qnorm(0.975),
  mean((pred$fit[, "upr"] - pred$fit[, "lwr"]) / (2 * qnorm(0.975) * sd_pred)))
```
For large degrees of freedom, such as for the daily spatial weather prediction in the project, this difference is negligible, and the `sd_pred` value is a suitable estimate of the prediction standard deviation.
