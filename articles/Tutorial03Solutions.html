<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Statistical Computing: Lab tutorial 3">
<title>Tutorial 03: Monte Carlo integration (solutions) • StatCompLab</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Tutorial 03: Monte Carlo integration (solutions)">
<meta property="og:description" content="Statistical Computing: Lab tutorial 3">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">StatCompLab</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">23.4.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Project01Hints.html">StatComp Project 1 (2021/22): Hints</a>
    <a class="dropdown-item" href="../articles/Tutorial01.html">Tutorial 01: R and linear models</a>
    <a class="dropdown-item" href="../articles/Tutorial01Solutions.html">Tutorial 01: R and linear models (solutions)</a>
    <a class="dropdown-item" href="../articles/Tutorial02.html">Tutorial 02: Optimization</a>
    <a class="dropdown-item" href="../articles/Tutorial02Solutions.html">Tutorial 02: Optimization (solutions)</a>
    <a class="dropdown-item" href="../articles/Tutorial03.html">Tutorial 03: Monte Carlo integration</a>
    <a class="dropdown-item" href="../articles/Tutorial03Solutions.html">Tutorial 03: Monte Carlo integration (solutions)</a>
    <a class="dropdown-item" href="../articles/Tutorial04.html">Tutorial 04: Uncertainty and integration</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/finnlindgren/StatCompLab/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Tutorial 03: Monte Carlo integration (solutions)</h1>
                        <h4 data-toc-skip class="author">Finn
Lindgren</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/finnlindgren/StatCompLab/blob/HEAD/vignettes/Tutorial03Solutions.Rmd" class="external-link"><code>vignettes/Tutorial03Solutions.Rmd</code></a></small>
      <div class="d-none name"><code>Tutorial03Solutions.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<ul>
<li>In this lab session you will explore Monte Carlo integration and
importance sampling.</li>
<li>Open your github repository clone project from Lab 2 (either on <a href="https://rstudio.cloud" class="external-link">https://rstudio.cloud</a> or on your own
computer and upgrade the <code>StatCompLab</code> package (see the <a href="%60StatCompLab%60%20page">https://finnlindgren.github.io/StatCompLab/</a>
for more details)</li>
<li>Save your work for this lab in one or several new files in the
project, and commit and push the changes to github (see Lab 2 for more
information)</li>
<li>In your code script, start with <code><a href="https://finnlindgren.github.io/StatCompLab">library(StatCompLab)</a></code> to
get access to the <code>arch_loglike</code> function needed for one of
the tasks.</li>
</ul>
<!--

The accompanying `Tutorial03Solutions` tutorial document contains the
solutions explicitly, to make it easier to review the material after the workshops.
You can also run the document in the Tutorials pane in RStudio.
-->
</div>
<div class="section level2">
<h2 id="overdispersed-poisson-distribution">Overdispersed Poisson distribution<a class="anchor" aria-label="anchor" href="#overdispersed-poisson-distribution"></a>
</h2>
<p>We’ll use an <em>overdispersed Poisson distribution</em> as the first
example. In an ordinary Poisson distribution <span class="math inline">\(Y\sim\mathsf{Poisson}(\lambda)\)</span> with
expectation <span class="math inline">\(\lambda\)</span>, the variance
is also <span class="math inline">\(\lambda\)</span>. The
<em>coefficient of variation</em> is defined as the ratio between the
standard deviation and the expectation, which gives <span class="math inline">\(1/\sqrt{\lambda}\)</span>. In real applications,
one often observes data where the coefficient of variation is larger
than the Poisson model would give. One way of dealing with that is to
add a <em>latent random effect</em>; a hidden layer of random values
that “nudges” the expectation for each observation, which increases the
observed coefficient of variation. The model can be written in two
steps: <span class="math display">\[
\begin{aligned}
X &amp; \sim \mathsf{Normal}(0,\sigma^2), \\
(Y|X=x) &amp; \sim \mathsf{Poisson}[\exp(\mu + x)],
\end{aligned}
\]</span> where the conditional expectation for <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span> and <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\lambda(\mu,x)=\exp(\mu+x)\)</span>, and <span class="math inline">\(\mu\)</span> is a (fixed) parameter. The
<em>marginal</em> expectation (but still conditionally on <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>) can be obtained via the tower
property (law of total expectation), <span class="math display">\[
\begin{aligned}
\mathsf{E}(Y|\mu,\sigma) &amp;= \mathsf{E}[\mathsf{E}(Y|X)] =
\mathsf{E}[\lambda(\mu,X)] = \mathsf{E}[\exp(\mu+X)] = \exp(\mu +
\sigma^2/2)
\end{aligned}
\]</span> where the last step comes from the expectation of a log-Normal
distribution. For multiple observations, we can write the model as <span class="math display">\[
\begin{aligned}
x_i &amp; \sim \mathsf{Normal}(0,\sigma^2), \text{ independent for each
$i=1,\dots,n$,}\\
(y_i|x_i) &amp; \sim \mathsf{Poisson}[\exp(\mu + x_i)], \text{
conditionally independent for each $i=1,\dots,n$}.
\end{aligned}
\]</span></p>
<p>Consider the following simulation code:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">rpois</a></span><span class="op">(</span><span class="fl">30</span>, lambda <span class="op">=</span> <span class="fl">3</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">30</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>What is the expectation of <span class="math inline">\(Y\)</span>?</p>
<ol style="list-style-type: decimal">
<li>
<strong>Theory exercise</strong>: Using the tower property (law of
total variance), theoretically derive an expression for <span class="math inline">\(\mathsf{Var}(Y)\)</span>. You can get the needed
log-Normal variance expression from <a href="https://en.wikipedia.org/wiki/Log-normal_distribution" class="external-link">https://en.wikipedia.org/wiki/Log-normal_distribution</a>
</li>
</ol>
<hr>
<p><strong>Solution:</strong></p>
<p><span class="math display">\[
\begin{aligned}
\mathsf{Var}(Y|\mu,\sigma) &amp;= \mathsf{E}[\mathsf{Var}(Y|X)] +
\mathsf{Var}[\mathsf{E}(Y|X)]
\\&amp;=
\mathsf{E}[\lambda(\mu,X)] + \mathsf{Var}[\lambda(\mu,X)]
\\&amp;=
\mathsf{E}[\exp(\mu+X)] +\mathsf{Var}[\exp(\mu+X)]
\\&amp;=
\exp(\mu + \sigma^2/2)
+
(\exp(\sigma^2)-1) \exp(2\mu + \sigma^2)
\\&amp;=
\exp(\mu + \sigma^2/2)
\left[
1
+
(\exp(\sigma^2)-1) \exp(\mu + \sigma^2/2)
\right]
\end{aligned}
\]</span> Since the second factor is always <span class="math inline">\(\geq 1\)</span>, this shows that the variance is
never smaller than the expectation.</p>
<hr>
<ol start="2" style="list-style-type: decimal">
<li>
<strong>Monte Carlo integration</strong>: Use Monte Carlo
integration to approximate the probability mass function <span class="math display">\[
\begin{aligned}
p_Y(m|\mu,\sigma)=\mathsf{P}(Y=m|\mu,\sigma) &amp;=
\int_{-\infty}^\infty \mathsf{P}(Y=m|\mu,\sigma,X=x) p_X(x|\sigma)
\,\mathrm{d}x
\end{aligned}
\]</span> for <span class="math inline">\(m=0,1,2,3,\dots,15\)</span>,
with <span class="math inline">\(\mu=\log(2)-1/2\)</span> and <span class="math inline">\(\sigma=1\)</span>. Check with the formulas above
what the resulting theoretical expectation is for <span class="math inline">\(Y\)</span> for this parameter combination.</li>
</ol>
<p>For this to be efficient, you should vectorise the calculations by
evaluating the conditional probability function for <span class="math inline">\(Y\)</span> over all the <span class="math inline">\(m\)</span> values at once, for each simulated
value <span class="math inline">\(x^{[k]}\sim\mathsf{Normal}(0,\sigma^2)\)</span>
value, for <span class="math inline">\(k=1,2,\dots,K\)</span>. Use <span class="math inline">\(K=10000\)</span> samples.</p>
<p>Plot the resulting probability mass function <span class="math inline">\(p_Y(m|\mu,\sigma)\)</span> together with the
ordinary Poisson probability mass function with the same expectation
value, <span class="math inline">\(\lambda = 2\)</span>. (Use the theory
above to convince yourself that these two models for <span class="math inline">\(Y\)</span> have the same expectation.)</p>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Vectorised over m</span></span>
<span><span class="va">mu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span></span>
<span><span class="va">K</span> <span class="op">&lt;-</span> <span class="fl">10000</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">0</span><span class="op">:</span><span class="fl">15</span></span>
<span><span class="va">P_Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">loop</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="va">K</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="va">P_Y</span> <span class="op">&lt;-</span> <span class="va">P_Y</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">dpois</a></span><span class="op">(</span><span class="va">m</span>, lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">mu</span> <span class="op">+</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">P_Y</span> <span class="op">&lt;-</span> <span class="va">P_Y</span> <span class="op">/</span> <span class="va">K</span></span>
<span></span>
<span><span class="co"># Plot the results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">suppressPackageStartupMessages</a></span><span class="op">(</span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>m <span class="op">=</span> <span class="va">m</span>,</span>
<span>                  P_Y <span class="op">=</span> <span class="va">P_Y</span>,</span>
<span>                  P_Poisson <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">dpois</a></span><span class="op">(</span><span class="va">m</span>, lambda <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Y</span>, col <span class="op">=</span> <span class="st">"MC"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Poisson</span>, col <span class="op">=</span> <span class="st">"Poisson"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Y</span>, col <span class="op">=</span> <span class="st">"MC"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Poisson</span>, col <span class="op">=</span> <span class="st">"Poisson"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="Tutorial03Solutions_files/figure-html/poisson-mc-show-1.png" width="576"></p>
<p>In the plot, the overdispersed Poisson probability function (that we
just computed) is compared with the plain Poisson probability function
for the same expectation value. Lines between values are included for
clarity. Note: In this case, the second approach is faster, but in other
situations the first approach is required, since it doesn’t require
storing all the random numbers at the same time, thus allowing for a
much larger <span class="math inline">\(K=n_{\text{mc}}\)</span> value
to be used.</p>
<hr>
<ol start="3" style="list-style-type: decimal">
<li>
<strong>Reusable function</strong>: Generalise the code to a
function <code>doverpois</code> (for “d”ensity for over-dispersed
Poisson) that takes <code>m</code>, <code>mu</code>, <code>sigma</code>,
and <code>K</code> as input and returns a <code>data.frame</code>
suitable for use with <code>ggplot</code>.</li>
</ol>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">doverpois</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">m</span>, <span class="va">mu</span>, <span class="va">sigma</span>, <span class="va">K</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">P_Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">m</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">loop</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="va">K</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">1</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span>    <span class="va">P_Y</span> <span class="op">&lt;-</span> <span class="va">P_Y</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">dpois</a></span><span class="op">(</span><span class="va">m</span>, lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">mu</span> <span class="op">+</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">P_Y</span> <span class="op">&lt;-</span> <span class="va">P_Y</span> <span class="op">/</span> <span class="va">K</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>m <span class="op">=</span> <span class="va">m</span>,</span>
<span>             P_Y <span class="op">=</span> <span class="va">P_Y</span>,</span>
<span>             P_Poisson <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">dpois</a></span><span class="op">(</span><span class="va">m</span>, lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">mu</span> <span class="op">+</span> <span class="va">sigma</span><span class="op">^</span><span class="fl">2</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<hr>
<p>Use the function to plot results for <span class="math inline">\(\mu=\log(8)-1/8\)</span>, <span class="math inline">\(\sigma = 1/2\)</span>, with <span class="math inline">\(m=0,1,\dots,30\)</span> by adding <code>P_Y</code>
and <code>P_Poisson</code> geoms to</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu">doverpois</span><span class="op">(</span>m <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span> <span class="op">-</span> <span class="fl">0.125</span>, sigma <span class="op">=</span> <span class="fl">0.5</span>, K <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">suppressPackageStartupMessages</a></span><span class="op">(</span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu">doverpois</span><span class="op">(</span>m <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span><span class="op">-</span><span class="fl">0.125</span>, sigma <span class="op">=</span> <span class="fl">0.5</span>, K <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Y</span>, col <span class="op">=</span> <span class="st">"MC"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Poisson</span>, col <span class="op">=</span> <span class="st">"Poisson"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Y</span>, col <span class="op">=</span> <span class="st">"MC"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">m</span>, <span class="va">P_Poisson</span>, col <span class="op">=</span> <span class="st">"Poisson"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="Tutorial03Solutions_files/figure-html/poisson-mc2-plot-1.png" width="576"></p>
<hr>
</div>
<div class="section level2">
<h2 id="archaeology-in-the-baltic-sea">Archaeology in the Baltic sea<a class="anchor" aria-label="anchor" href="#archaeology-in-the-baltic-sea"></a>
</h2>
<div class="figure">
<img src="images/Waldemarkreuz_wikipedia.png" alt=""><p class="caption">The Waldemar cross, source: Wikipedia</p>
</div>
Original inscription, in Latin:
<blockquote>
``Anno Domini MCCCLXI feria III post Jacobi ante portas Visby in manibus
Danorum ceciderunt Gutenses, hic sepulti, orate pro eis!’’
</blockquote>
<p><!--
<blockquote>
    "I Herrens {\aa}r 1361, tredje dagen efter S:t Jacob, f\"oll utanf\"or
    Visbys portar gutarna i danskarnas h\"ander. H\"ar \"ar de begravda.
    Bed f\"or dem."
</blockquote>
--></p>
English translation:
<blockquote>
``In the year of our Lord 1361, on the third day after St. Jacob, the
Goth fell outside the gates of Visby at the hands of the Danish. They
are buried here. Pray for them!’’
</blockquote>
<p>Strategically located in the middle of the Baltic sea, the island of
Gotland had shifting periods of being partly self-governed, and in
partial control by the Hanseatic trading alliance, Sweden, Denmark, and
the Denmark-Norway-Sweden union, until settling as part of Sweden in
1645. Gotland has an abundance of archaeological treasures, with coins
dating back to Viking era trade routes via Russia to the Arab
Caliphates. and captured the rich Hanseatic town of Visby.</p>
<p>In 1361 the Danish king Valdemar Atterdag conquered Gotland. The
conquest was followed by a plunder of Visby. Most of the defenders
(primarily local farmers that could not take shelter inside the city
walls) were killed in the attack and are buried in a field,
<em>Korsbetningen</em> (Literal translation: <em>the grazing field that
is marked by a cross</em>, as shown in the picture), outside of the
walls of Visby.</p>
<p>In the 1920s the gravesite was subject to several archaeological
excavations. A total of <span class="math inline">\(493\)</span> femurs
(thigh bones) (<span class="math inline">\(256\)</span> left, and <span class="math inline">\(237\)</span> right) were found. We want to figure
out how many persons were likely buried at the gravesite. It must
reasonably have been at least <span class="math inline">\(256\)</span>,
but how many more?</p>
<div class="section level3">
<h3 id="statistical-model">Statistical model<a class="anchor" aria-label="anchor" href="#statistical-model"></a>
</h3>
<p>To build a simple model for this problem, we assume that the number
of left (<span class="math inline">\(y_1=256\)</span>) and right (<span class="math inline">\(y_2=237\)</span>) femurs are two independent
observations from a <span class="math inline">\(\mathsf{Bin}(N,\phi)\)</span> distribution. Here
<span class="math inline">\(N\)</span> is the total number of people
buried and <span class="math inline">\(\phi\)</span> is the probability
of finding a femur, left or right, and both <span class="math inline">\(N\)</span> and <span class="math inline">\(\phi\)</span> are unknown parameters.</p>
<p>The probability function for a single observation <span class="math inline">\(y\sim\mathsf{Bin}(N,\phi)\)</span> is <span class="math display">\[\begin{align*}
p(y|N,\phi) &amp;= {N \choose y} \phi^y (1-\phi)^{N-y} .
\end{align*}\]</span> The function <code><a href="../reference/arch_loglike.html">arch_loglike()</a></code> in the
<code>StatCompLab</code> package evaluates the combined log-likelihood
<span class="math inline">\(\log[p(\boldsymbol{y}|N,\phi)]\)</span> for
a collection <span class="math inline">\(\boldsymbol{y}\)</span> of
<span class="math inline">\(y\)</span>-observations. If a
<code>data.frame</code> with columns <code>N</code> and <code>phi</code>
is provided, the log-likelihood for each row-pair <span class="math inline">\((N,\phi)\)</span> is returned.</p>
<p>The combined <span class="math inline">\(l(y_1,y_2|N,\theta)=\log
p(y_1,y_2|N,\phi)\)</span> for the data set <span class="math inline">\(\{y_1,y_2\}\)</span> is then given by <span class="math display">\[
\begin{aligned}
l(y_1,y_2|N,\theta) &amp;= -\log\Gamma(y_1+1) - \log\Gamma(y_2+1)
\\&amp;\phantom{=~}
- \log\Gamma(N-y_1+1) - \log\Gamma(N-y_2+1)
+ 2\log\Gamma(N+1)
\\&amp;\phantom{=~}
+ (y_1+y_2) \log(\phi) + (2 N - y_1 - y_2)\log(1-\phi)
\end{aligned}
\]</span></p>
<p>The task is to use Monte Carlo integration to estimate the posterior
expectations of <span class="math inline">\(N\)</span> and <span class="math inline">\(\phi\)</span>, when the prior distributions are
<span class="math inline">\(N\sim\mathsf{Geom}(\xi)\)</span>, <span class="math inline">\(0&lt;\xi&lt;1\)</span>, and <span class="math inline">\(\phi\sim\mathsf{Beta}(a, b)\)</span>, <span class="math inline">\(a,b&gt;0\)</span>.</p>
<p>The mathematical definitions are: Let <span class="math inline">\(N\)</span> have a <span class="math inline">\(\mathsf{Geom}(\xi)\)</span>, <span class="math inline">\(\xi&gt;0\)</span>, prior distribution, and let
<span class="math inline">\(\phi\)</span> have a <span class="math inline">\(\mathsf{Beta}(a,b)\)</span>, <span class="math inline">\(a,b&gt;0\)</span>, prior distribution: <span class="math display">\[
\begin{aligned}
p_N(n) = \mathsf{P}(N=n) &amp;= \xi\,(1-\xi)^n,\quad n=0,1,2,3,\dots, \\
p_\phi(\phi) &amp;= \frac{\phi^{a-1}(1-\phi)^{b-1}}{B(a,b)}, \quad
\phi\in[0,1] .
\end{aligned}
\]</span> and the probability mass function <span class="math inline">\(p_N(n)\)</span> can be evaluated with
<code><a href="https://rdrr.io/r/stats/Geometric.html" class="external-link">dgeom()</a></code> in R, and the density <span class="math inline">\(p_\phi(\phi)\)</span> can be evaluated with
<code>dbeta</code>.</p>
</div>
<div class="section level3">
<h3 id="bayesian-estimation">Bayesian estimation<a class="anchor" aria-label="anchor" href="#bayesian-estimation"></a>
</h3>
<p>Before the excavation took place, the archaeologist believed that
around <span class="math inline">\(1000\)</span> individuals were
buried, and that they would find around half on the femurs. To encode
that belief in the Bayesian analysis, set <span class="math inline">\(\xi=1/(1+1000)\)</span>, which corresponds to an
expected total count of <span class="math inline">\(1000\)</span>, and
<span class="math inline">\(a=b=2\)</span>, which makes <span class="math inline">\(\phi\)</span> more likely to be close to <span class="math inline">\(1/2\)</span> than to <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>.</p>
<p>The posterior density/probability function for <span class="math inline">\((N,\phi|\boldsymbol{y})\)</span> is <span class="math display">\[
\begin{aligned}
p_{N,\phi|\boldsymbol{y}}(n,\phi|\boldsymbol{y}) &amp;=
\frac{p_{N,\phi,\boldsymbol{y}}(n,\phi,\boldsymbol{y})}{p_{\boldsymbol{y}}(\boldsymbol{y})}
=
\frac{p_N(n)p_\phi(\phi)p(\boldsymbol{y}|n,\phi)}{p_{\boldsymbol{y}}(\boldsymbol{y})}
\end{aligned}
\]</span></p>
<p>We can estimate <span class="math inline">\(p_{\boldsymbol{y}}(\boldsymbol{y})\)</span> with
Monte Carlo integration, the the same time as using importance sampling
to estimate the posterior expectations. The theoretical expressions
<span class="math display">\[
\begin{aligned}
p_{\boldsymbol{y}}(\boldsymbol{y}) &amp;=
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1
p_{N,\phi,\boldsymbol{y}}(n,\phi,\boldsymbol{y}) \,\mathrm{d}\phi =
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1 p(\boldsymbol{y}|n,\phi) p_N(n)
p_\phi(\phi) \,\mathrm{d}\phi\\
\mathsf{E}(N|\boldsymbol{y}) &amp;=
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1
n\,p_{N,\phi|\boldsymbol{y}}(n,\phi) \,\mathrm{d}\phi =
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1
n\,\frac{p(\boldsymbol{y}|n,\phi)}{p_{\boldsymbol{y}}(\boldsymbol{y})}
p_N(n) p_\phi(\phi) \,\mathrm{d}\phi\\
\mathsf{E}(\phi|\boldsymbol{y}) &amp;=
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1
\phi\,p_{N,\phi|\boldsymbol{y}}(n,\phi) \,\mathrm{d}\phi =
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1
\phi\,\frac{p(\boldsymbol{y}|n,\phi)}{p_{\boldsymbol{y}}(\boldsymbol{y})}
p_N(n) p_\phi(\phi)
\,\mathrm{d}\phi
\end{aligned}
\]</span></p>
</div>
<div class="section level3">
<h3 id="monte-carlo-integration">Monte Carlo integration<a class="anchor" aria-label="anchor" href="#monte-carlo-integration"></a>
</h3>
<p>What might a good choice of sampling distribution be? In this first
approach to the problem, let’s use the prior distributions as sampling
distributions for the Monte Carlo integration. This means that we need
to sample <span class="math inline">\(n^{[k]}\sim\mathsf{Geom}(\xi)\)</span> and <span class="math inline">\(\phi^{[k]}\sim\mathsf{Beta}(a,b)\)</span>, and
compute Monte Carlo estimates <span class="math display">\[
\begin{aligned}
\widehat{p}_{\boldsymbol{y}}(\boldsymbol{y}) &amp;=
\frac{1}{K}
  \sum_{k=1}^K p(\boldsymbol{y}|n^{[k]},\phi^{[k]})\\
\widehat{\mathsf{E}}(N|\boldsymbol{y}) &amp;=
  \frac{1}{K \widehat{p}_{\boldsymbol{y}}(\boldsymbol{y})}
  \sum_{k=1}^K n^{[k]} p(\boldsymbol{y}|n^{[k]},\phi^{[k]})\\
\widehat{\mathsf{E}}(\phi|\boldsymbol{y}) &amp;=
  \frac{1}{K \widehat{p}_{\boldsymbol{y}}(\boldsymbol{y})}
  \sum_{k=1}^K \phi^{[k]} p(\boldsymbol{y}|n^{[k]},\phi^{[k]})\\
\end{aligned}
\]</span> Write a function <code>estimate</code> that takes inputs
<code>y</code>, <code>xi</code>, <code>a</code>, <code>b</code>, and
<code>K</code> and implements the above Monte Carlo integration
method.</p>
<p>Test the function by running
<code>estimate(y=c(237,256), xi=1/1001, a=0.5, b=0.5, K=10000)</code></p>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">estimate</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">xi</span>, <span class="va">a</span>, <span class="va">b</span>, <span class="va">K</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">samples</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>    N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Geometric.html" class="external-link">rgeom</a></span><span class="op">(</span><span class="va">K</span>, prob <span class="op">=</span> <span class="va">xi</span><span class="op">)</span>,</span>
<span>    phi <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html" class="external-link">rbeta</a></span><span class="op">(</span><span class="va">K</span>, shape1 <span class="op">=</span> <span class="va">a</span>, shape2 <span class="op">=</span> <span class="va">b</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="va">loglike</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/arch_loglike.html">arch_loglike</a></span><span class="op">(</span>param <span class="op">=</span> <span class="va">samples</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span></span>
<span>  <span class="va">p_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">loglike</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>p_y <span class="op">=</span> <span class="va">p_y</span>,</span>
<span>    E_N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">samples</span><span class="op">$</span><span class="va">N</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">loglike</span><span class="op">)</span> <span class="op">/</span> <span class="va">p_y</span><span class="op">)</span>,</span>
<span>    E_phi <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">samples</span><span class="op">$</span><span class="va">phi</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">loglike</span><span class="op">)</span> <span class="op">/</span> <span class="va">p_y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">estimate</span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">237</span>, <span class="fl">256</span><span class="op">)</span>, xi <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">1001</span>, a <span class="op">=</span> <span class="fl">0.5</span>, b <span class="op">=</span> <span class="fl">0.5</span>, K <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##          p_y          E_N        E_phi </span></span>
<span><span class="co">## 6.360064e-06 9.884083e+02 3.694532e-01</span></span></code></pre>
<hr>
<p>Note: as shown in lecture 3, the conditional posterior distribution
for <span class="math inline">\(\phi\)</span> for fixed <span class="math inline">\(N=n\)</span> is <span class="math inline">\((\phi|n,\boldsymbol{y})\sim
\mathsf{Beta}(a+y_1+y_2,b+2n-y_1-y_2)\)</span>. This can be used to
construct a potentially more efficient method, where each <span class="math inline">\(\phi^{[k]}\)</span> is sampled conditionally on
<span class="math inline">\(n^{[k]}\)</span>, and the integration
importance weights adjusted appropriately.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Finn Lindgren.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
