<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tutorial 04: Uncertainty and integration • StatCompLab</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Tutorial 04: Uncertainty and integration">
<meta property="og:description" content="Statistical Computing: Lab tutorial 4">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">StatCompLab</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">21.4.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Tutorial01.html">Tutorial 01: R and linear models</a>
    </li>
    <li>
      <a href="../articles/Tutorial01Solutions.html">Tutorial 01: R and linear models (solutions)</a>
    </li>
    <li>
      <a href="../articles/Tutorial02.html">Tutorial 02: Optimization</a>
    </li>
    <li>
      <a href="../articles/Tutorial02Solutions.html">Tutorial 02: Optimization (solutions)</a>
    </li>
    <li>
      <a href="../articles/Tutorial03.html">Tutorial 03: Monte Carlo integration</a>
    </li>
    <li>
      <a href="../articles/Tutorial03Solutions.html">Tutorial 03: Monte Carlo integration (solutions)</a>
    </li>
    <li>
      <a href="../articles/Tutorial04.html">Tutorial 04: Uncertainty and integration</a>
    </li>
    <li>
      <a href="../articles/Tutorial04Solutions.html">Tutorial 04: Uncertainty and integration (solutions)</a>
    </li>
    <li>
      <a href="../articles/Quiz1Solution.html">Quiz 1 Solution (StatComp 2021/22)</a>
    </li>
    <li>
      <a href="../articles/T4sol.html">Tutorial 04: Uncertainty and integration (full solution)</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/finnlindgren/StatCompLab/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="Tutorial04_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Tutorial 04: Uncertainty and integration</h1>
                        <h4 data-toc-skip class="author">Finn Lindgren</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/finnlindgren/StatCompLab/blob/HEAD/vignettes/Tutorial04.Rmd" class="external-link"><code>vignettes/Tutorial04.Rmd</code></a></small>
      <div class="hidden name"><code>Tutorial04.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>In this lab session you will explore</p>
<ul>
<li>using RMarkdown to organise text and code</li>
<li>maximum likelihood estimator sampling distributions and approximate confidence interval construction</li>
<li>Laplace approximation and importance sampling for approximate Bayesian credible interval construction</li>
</ul>
<ol style="list-style-type: decimal">
<li>Clone your <code>lab04-*</code> repository from <a href="https://github.com/StatComp21/" class="external-link">https://github.com/StatComp21/</a> wither on your own computer (new Project from version control) or to <a href="https://rstudio.cloud" class="external-link">https://rstudio.cloud</a>
</li>
<li>If on rstudio.cloud, setup <code>GITHUB_PAT</code> credentials, like before.</li>
<li>Upgrade/install the <code>StatCompLab</code> package, see <a href="https://finnlindgren.github.io/StatCompLab/">https://finnlindgren.github.io/StatCompLab/</a>
</li>
<li>The repository has two files, <code>RMDemo.Rmd</code> and <code>my_code.R</code>. Make a copy of <code>RMDemo.Rmd</code>, and call it <code>Lab4.Rmd</code>
</li>
<li>During this lab, modify the <code>Lab4.Rmd</code> document and add new code and text commentary for the lab to the document. (You can remove the demonstration parts of the file when you don’t need them anymore, and/or keep a separate copy of it.) When pressing the “knit” button, the RMarkdown file will be run in its own R environment, so you need to include any needed <code><a href="https://rdrr.io/r/base/library.html" class="external-link">library()</a></code> calls in a code chnk in the file, normally an initial “setup” chunk.</li>
</ol>
<hr>
<p><strong>Solution:</strong></p>
<p>The accompanying <code>Tutorial04Solutions</code> tutorial/vignette documents contain the solutions explicitly, to make it easier to review the material after the workshops. The separate <code>T4sol.Rmd</code> document at <a href="https://github.com/finnlindgren/StatCompLab/blob/main/vignettes/articles/T4sol.Rmd" class="external-link">https://github.com/finnlindgren/StatCompLab/blob/main/vignettes/articles/T4sol.Rmd</a> is the source document for the standalone solution shown in <code>T4sol</code> on the <code>StatCompLab</code> website.</p>
<hr>
</div>
<div class="section level2">
<h2 id="three-alternatives-for-poisson-parameter-confidence-intervals">Three alternatives for Poisson parameter confidence intervals<a class="anchor" aria-label="anchor" href="#three-alternatives-for-poisson-parameter-confidence-intervals"></a>
</h2>
<p>Consider the Poisson model for observations <span class="math inline">\(\boldsymbol{y}=\{y_1,\dots,y_n\}\)</span>: <span class="math display">\[
\begin{aligned}
y_i &amp; \sim \mathsf{Poisson}(\lambda), \quad\text{independent for $i=1,\dots,n$.}
\end{aligned}
\]</span> that has joint probability mass function <span class="math display">\[
p(\boldsymbol{y}|\lambda) = \exp(-n\lambda) \prod_{i=1}^n \frac{\lambda^{y_i}}{y_i!}
\]</span> In the week 4 lecture, two parameterisations were considered. We now add a third option:</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\theta = \lambda\)</span>, and <span class="math inline">\(\widehat{\theta}_\text{ML}=\frac{1}{n}\sum_{i=1}^n y_i = \overline{y}\)</span>
</li>
<li>
<span class="math inline">\(\theta = \sqrt{\lambda}\)</span>, and <span class="math inline">\(\widehat{\theta}_\text{ML}=\sqrt{\overline{y}}\)</span>
</li>
<li>
<span class="math inline">\(\theta = \log(\lambda)\)</span>, and <span class="math inline">\(\widehat{\theta}_\text{ML}=\log\left(\overline{y}\right)\)</span>
</li>
</ol>
<p>From the week 4 lecture, we know that the inverse expected Fisher information is <span class="math inline">\(\lambda/n\)</span> for case 1 and <span class="math inline">\(1/(4n)\)</span> for case 2. For case 3, show that the inverse expected Fisher information is <span class="math inline">\(1/(n\lambda)\)</span>.</p>
<!--

For case 3, the negated log-likelihood is
$$
\wt{l}(\theta) = n e^\theta - \theta \sum_{i=1}^n y_i + \text{constant}
$$
with 1st order derivative
$$
\frac{\partial}{\partial\theta}\wt{l}(\theta) = n e^\theta - \sum_{i=1}^n y_i
$$
which shows that $\wh{\theta}_\text{ML}=\log(\ol{y})$, and 2nd order derivative
$$
\frac{\partial^2}{\partial\theta^2}\wt{l}(\theta) = n e^\theta
$$
which is equal to $n\lambda$ for all $y_i$ values, so the inverse of the expected Hessian is $1/(n\lambda)$.
-->
<div class="section level3">
<h3 id="interval-construction">Interval construction<a class="anchor" aria-label="anchor" href="#interval-construction"></a>
</h3>
<p>Use the approximation method for large <span class="math inline">\(n\)</span> from the lecture to construct approximate confidence intervals for <span class="math inline">\(\lambda\)</span> using each of the three parameterisations. Define three functions, CI1, CI2, and CI3, each taking paramters</p>
<ul>
<li>
<code>y</code>: a vector of observed values</li>
<li>
<code>alpha</code>: the nominal error probability of the confidence intervals</li>
</ul>
<p>To avoid having to specify <code>alpha</code> in a common case, you can use <code>alpha = 0.05</code> in the function argument definition to set a default value.</p>
<p>The function <code>pmax</code> may be useful (see its help text).</p>
<!--


-->
<p>You can use the following code to test your functions, storing each interval as a row of a matrix with <code>rbind</code> (“bind” as “rows”, see also <code>cbind</code> for combining columns):</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span>, lambda <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></code></pre></div>
<pre><code><span class="co">## [1] 0 2 2 2 4</span></code></pre>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">CI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span>
  <span class="st">"Method 1"</span> <span class="op">=</span> <span class="fu">CI1</span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,
  <span class="st">"Method 2"</span> <span class="op">=</span> <span class="fu">CI2</span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,
  <span class="st">"Method 3"</span> <span class="op">=</span> <span class="fu">CI3</span><span class="op">(</span><span class="va">y</span><span class="op">)</span>
<span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">CI</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Lower"</span>, <span class="st">"Upper"</span><span class="op">)</span></code></pre></div>
<p>We can print the result as a table in our RMarkdown by using a separate codechunk, calling the <code><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">knitr::kable</a></code> function:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">CI</span><span class="op">)</span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="right">Lower</th>
<th align="right">Upper</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Method 1</td>
<td align="right">0.7604099</td>
<td align="right">3.239590</td>
</tr>
<tr class="even">
<td align="left">Method 2</td>
<td align="right">0.9524829</td>
<td align="right">3.431663</td>
</tr>
<tr class="odd">
<td align="left">Method 3</td>
<td align="right">1.0761094</td>
<td align="right">3.717094</td>
</tr>
</tbody>
</table>
<p>Will all three methods always produce a valid interval? Consider the possible values of <span class="math inline">\(\overline{y}\)</span>. Experiment with different values of <code>n</code> and <code>lambda</code> in the simulation of <code>y</code>.</p>
<!--

When $\ol{y}=0$, the first method produces a single point as "interval".

The third method fails if $\ol{y}=0$, due to log of zero.

This can happen when $n$ or $\lambda$ are close to zero.
-->
<p>For each approximate confidence interval construction method, we might ask the question of whether it fulfils the definition of an actual confidence interval construction method; that <span class="math inline">\(\mathsf{P}_{\boldsymbol{y}|\theta}(\theta\in \text{CI}(\boldsymbol{y})|\theta)\geq 1-\alpha\)</span> for all <span class="math inline">\(\theta\)</span> (or at least for a relevant subset of the parameter space). In coursework project 1, you will investigate the accuracy of some approximate confidence interval construction methods.</p>
</div>
</div>
<div class="section level2">
<h2 id="bayesian-credible-intervals">Bayesian credible intervals<a class="anchor" aria-label="anchor" href="#bayesian-credible-intervals"></a>
</h2>
<p>Assume a true value of <span class="math inline">\(\lambda=10\)</span>, and simulate a sample of <span class="math inline">\(\boldsymbol{y}\)</span> of size <span class="math inline">\(n=5\)</span>.</p>
<!--


-->
<p>Now consider a Bayesian version of the Poisson model, with prior model <span class="math display">\[
\lambda \sim \mathsf{Exp}(a)
\]</span> that has probability density function <span class="math inline">\(p(\lambda) = a \exp(-a \lambda)\)</span>.</p>
<p>One can show that the exact posterior distribution for <span class="math inline">\(\lambda\)</span> given <span class="math inline">\(\boldsymbol{y}\)</span> is a <span class="math inline">\(\mathsf{Gamma}(1 + \sum_{i=1}^n y_i, a + n)\)</span> distribution (using the shape&amp;rate parameterisation), and credible intervals can be constructed from quantiles of this distribution.</p>
<p>In cases where the theoretical construction is impractical, an alternative is to instead construct samples from the posterior distribution, and extract empirical quantiles from this sample. Here, we will use importance sampling to achieve this.</p>
<p>Let <span class="math inline">\(\theta=\log(\lambda)\)</span>, so that <span class="math inline">\(\lambda=\exp(\theta)\)</span>. Show that the prior probability density for <span class="math inline">\(\theta\)</span> is <span class="math inline">\(p(\theta)=a \exp\left( \theta-ae^\theta \right)\)</span>.</p>
<div class="section level3">
<h3 id="gaussian-approximation">Gaussian approximation<a class="anchor" aria-label="anchor" href="#gaussian-approximation"></a>
</h3>
<!--

From probability theory, we know that $p(\theta)=p(\lambda) \frac{d\lambda(\theta)}{d\theta}$, so that
$$
p(\theta) = a \exp(-a\lambda) \exp(\theta) = a \exp\left( \theta-ae^\theta \right)
$$
-->
<p>The posterior density function for <span class="math inline">\(\theta\)</span> is <span class="math display">\[
p(\theta|\boldsymbol{y}) = \frac{p(\theta) p(\boldsymbol{y}|\theta)}{p(\boldsymbol{y})}
\]</span> with log-density <span class="math display">\[
\log p(\theta|\boldsymbol{y}) = \text{const} + \theta (1 + n\overline{y}) - (a+n)\exp(\theta) ,
\]</span> and by taking derivatives we find the mode at <span class="math inline">\(\widetilde{\theta}=\log\left(\frac{1+n\overline{y}}{a+n}\right)\)</span>, and negated Hessian <span class="math inline">\(1+n\overline{y}\)</span> at the mode.</p>
<p>With this information we can construct a Gaussian approximation to the posterior distribution, <span class="math inline">\(\widetilde{p}(\theta|\boldsymbol{y})\sim\mathsf{Normal}(\widetilde{\theta},\frac{1}{1+n\overline{y}})\)</span>.</p>
</div>
<div class="section level3">
<h3 id="importance-sampling">Importance sampling<a class="anchor" aria-label="anchor" href="#importance-sampling"></a>
</h3>
<p>Simulate a sample <span class="math inline">\(\boldsymbol{x}=\{x_1,\dots,x_m\}\)</span> from this Gaussian approximation of the posterior distribution, for some large <span class="math inline">\(m &gt; 10000\)</span>, with hyperparameter <span class="math inline">\(a=1/5\)</span>.</p>
<!--


-->
<p>We need to calculate unnormalised <em>importance weights</em> <span class="math inline">\(w_k\)</span>, <span class="math inline">\(k=1,\dots,m\)</span>, <span class="math display">\[
w_k = \left.\frac{p(\theta)p(\boldsymbol{y}|\theta)}{\widetilde{p}(\theta|\boldsymbol{y})}\right|_{\theta=x_k} .
\]</span> Due to lack of normalisation, these “raw” weights cannot be represented accurately in the computer. To get around that issue, first compute the logarithm of the weights, <span class="math inline">\(\log(w_k)\)</span>, and then new, equivalent unnormalised weights <span class="math inline">\(\widetilde{w}_k=\exp[\log(w_k) - \max_j \log(w_j)]\)</span>.</p>
<!--


-->
<p>Look at the help text for the function <code>wquantile</code> (in the StatCompLab package, from version 0.4.0) that computes quantiles from a weighted sample, and construct a 95% credible interval for <span class="math inline">\(\theta\)</span> using the <span class="math inline">\(\boldsymbol{x}\)</span> sample and associate weights, and then transform it into a credible interval for <span class="math inline">\(\lambda\)</span></p>
<!--


-->
</div>
<div class="section level3">
<h3 id="cumulative-distribution-function-comparison">Cumulative distribution function comparison<a class="anchor" aria-label="anchor" href="#cumulative-distribution-function-comparison"></a>
</h3>
<p>With <code>ggplot</code>, use <code>geom_function</code> to plot the theoretical posterior cumulative distribution function for <span class="math inline">\(\lambda\)</span> (the CDF from the Gamma distribution given above, see <code><a href="https://rdrr.io/r/stats/GammaDist.html" class="external-link">pgamma()</a></code>) and compare it to the approximation given by the importance sampling. The <code><a href="../reference/stat_ewcdf.html">stat_ewcdf()</a></code> function from the StatCompLab should be used to plot the cdf for the weighted sample <span class="math inline">\(\lambda_k=\exp(x_k)\)</span>, with (unnormalised) weights <span class="math inline">\(w_k\)</span>. Also include the unweighted sample, with <code>stat_ecwf()</code>. How close does the approximations come to the true posterior distribution?</p>
<!--

The importance sampling version is virtually indistinguishable from the true posterior distribution.
The unweighted sample is very close to the true posterior distribution; for this model, the Gaussian approximation of the posterior distribution of $\log(\lambda)$ is an excellent approximation even before we add the importance sampling step.

```
## Registered S3 method overwritten by 'spatstat.geom':
##   method     from
##   print.boxx cli
```

<img src="Tutorial04_files/figure-html/ecdf-show-1.png" width="576" />
-->
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Finn Lindgren.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.2.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
