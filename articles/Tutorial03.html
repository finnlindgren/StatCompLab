<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Tutorial 03: Monte Carlo integration ‚Ä¢ StatCompLab</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Tutorial 03: Monte Carlo integration">
<meta name="description" content="Statistical Computing: Lab tutorial 3">
<meta property="og:description" content="Statistical Computing: Lab tutorial 3">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">StatCompLab</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">25.4.9</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/Project_Example_Solution.html">StatComp Project Example Solution: Numerical Statistics</a></li>
    <li><a class="dropdown-item" href="../articles/Project_Example.html">StatComp Project Example: Numerical statistics</a></li>
    <li><a class="dropdown-item" href="../articles/Project01.html">StatComp Project 1 (2022/23): Simulation and sampling</a></li>
    <li><a class="dropdown-item" href="../articles/Project01Hints.html">StatComp Project 1 (2022/23): Hints</a></li>
    <li><a class="dropdown-item" href="../articles/Project02.html">StatComp Project 2: Scottish weather</a></li>
    <li><a class="dropdown-item" href="../articles/Project02Hints.html">StatComp Project 2 (2022/23): Hints</a></li>
    <li><a class="dropdown-item" href="../articles/Quiz1Solution.html">Quiz 1 Solution (StatComp 2021/22)</a></li>
    <li><a class="dropdown-item" href="../articles/T4sol.html">Tutorial 04: Uncertainty and integration (full solution)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial01.html">Tutorial 01: R and linear models</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial01Solutions.html">Tutorial 01: R and linear models (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial02.html">Tutorial 02: Optimization</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial02Solutions.html">Tutorial 02: Optimization (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial03.html">Tutorial 03: Monte Carlo integration</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial03Solutions.html">Tutorial 03: Monte Carlo integration (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial04.html">Tutorial 04: Uncertainty and integration</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial04Solutions.html">Tutorial 04: Uncertainty and integration (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial06.html">Tutorial 06: Prediction assessment with proper scores</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial06Solutions.html">Tutorial 06: Prediction assessment with proper scores (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial07.html">Tutorial 07: Data wrangling and cross validation</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial07Solutions.html">Tutorial 07: Data wrangling and cross validation (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial08.html">Tutorial 08: Floating point computations and least squares</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial08Solutions.html">Tutorial 08: Floating point computations and least squares (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial09.html">Tutorial 09: Bootstrap and Pareto smoothed importance sampling</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial09Solutions.html">Tutorial 09: Bootstrap and Pareto smoothed importance sampling (solutions)</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/finnlindgren/StatCompLab/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Tutorial 03: Monte Carlo integration</h1>
                        <h4 data-toc-skip class="author">Finn
Lindgren</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/finnlindgren/StatCompLab/blob/main/vignettes/Tutorial03.Rmd" class="external-link"><code>vignettes/Tutorial03.Rmd</code></a></small>
      <div class="d-none name"><code>Tutorial03.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<ul>
<li>In this lab session you will explore Monte Carlo integration and
importance sampling.</li>
<li>Open your github repository clone project from Lab 2 (either on <a href="https://rstudio.cloud" class="external-link">https://rstudio.cloud</a> or on your own
computer and upgrade the <code>StatCompLab</code> package (see the <a href="%60StatCompLab%60%20page">https://finnlindgren.github.io/StatCompLab/</a>
for more details)</li>
<li>Save your work for this lab in one or several new files in the
project, and commit and push the changes to github (see Lab 2 for more
information)</li>
<li>In your code script, start with <code><a href="https://finnlindgren.github.io/StatCompLab">library(StatCompLab)</a></code> to
get access to the <code>arch_loglike</code> function needed for one of
the tasks.</li>
</ul>
<hr>
<p><strong>Solution:</strong></p>
<p>The accompanying <code>Tutorial03Solutions</code> tutorial document
contains the solutions explicitly, to make it easier to review the
material after the workshops. You can also run the document in the
Tutorials pane in RStudio.</p>
<hr>
</div>
<div class="section level2">
<h2 id="overdispersed-poisson-distribution">Overdispersed Poisson distribution<a class="anchor" aria-label="anchor" href="#overdispersed-poisson-distribution"></a>
</h2>
<p>We‚Äôll use an <em>overdispersed Poisson distribution</em> as the first
example. In an ordinary Poisson distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>‚àº</mo><mrow><mi>ùñØ</mi><mi>ùóà</mi><mi>ùóÇ</mi><mi>ùóå</mi><mi>ùóå</mi><mi>ùóà</mi><mi>ùóá</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">Y\sim\mathsf{Poisson}(\lambda)</annotation></semantics></math>
with expectation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>,
the variance is also
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.
The <em>coefficient of variation</em> is defined as the ratio between
the standard deviation and the expectation, which gives
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><msqrt><mi>Œª</mi></msqrt></mrow><annotation encoding="application/x-tex">1/\sqrt{\lambda}</annotation></semantics></math>.
In real applications, one often observes data where the coefficient of
variation is larger than the Poisson model would give. One way of
dealing with that is to add a <em>latent random effect</em>; a hidden
layer of random values that ‚Äúnudges‚Äù the expectation for each
observation, which increases the observed coefficient of variation. The
model can be written in two steps:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>X</mi></mtd><mtd columnalign="left" style="text-align: left"><mo>‚àº</mo><mrow><mi>ùñ≠</mi><mi>ùóà</mi><mi>ùóã</mi><mi>ùóÜ</mi><mi>ùñ∫</mi><mi>ùóÖ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mrow><mo stretchy="true" form="prefix">(</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>‚àº</mo><mrow><mi>ùñØ</mi><mi>ùóà</mi><mi>ùóÇ</mi><mi>ùóå</mi><mi>ùóå</mi><mi>ùóà</mi><mi>ùóá</mi></mrow><mrow><mo stretchy="true" form="prefix">[</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>+</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
X &amp; \sim \mathsf{Normal}(0,\sigma^2), \\
(Y|X=x) &amp; \sim \mathsf{Poisson}[\exp(\mu + x)],
\end{aligned}
</annotation></semantics></math> where the conditional expectation for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">X=x</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œº</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>,</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>+</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\lambda(\mu,x)=\exp(\mu+x)</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œº</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
is a (fixed) parameter. The <em>marginal</em> expectation (but still
conditionally on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œº</mi><annotation encoding="application/x-tex">\mu</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œÉ</mi><annotation encoding="application/x-tex">\sigma</annotation></semantics></math>)
can be obtained via the tower property (law of total expectation),
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>ùñ§</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><mi>Œº</mi><mo>,</mo><mi>œÉ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>ùñ§</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>ùñ§</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Y</mi><mo stretchy="false" form="prefix">|</mo><mi>X</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>ùñ§</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>Œª</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>,</mo><mi>X</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mi>ùñ§</mi><mrow><mo stretchy="true" form="prefix">[</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>+</mo><mi>X</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mo>=</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>+</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mi>/</mi><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\mathsf{E}(Y|\mu,\sigma) &amp;= \mathsf{E}[\mathsf{E}(Y|X)] = \mathsf{E}[\lambda(\mu,X)] = \mathsf{E}[\exp(\mu+X)] = \exp(\mu + \sigma^2/2)
\end{aligned}
</annotation></semantics></math> where the last step comes from the
expectation of a log-Normal distribution. For multiple observations, we
can write the model as
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>x</mi><mi>i</mi></msub></mtd><mtd columnalign="left" style="text-align: left"><mo>‚àº</mo><mrow><mi>ùñ≠</mi><mi>ùóà</mi><mi>ùóã</mi><mi>ùóÜ</mi><mi>ùñ∫</mi><mi>ùóÖ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mrow><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> independent for each </mtext><mspace width="0.333em"></mspace></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi></mrow><mtext mathvariant="normal">,</mtext></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>‚àº</mo><mrow><mi>ùñØ</mi><mi>ùóà</mi><mi>ùóÇ</mi><mi>ùóå</mi><mi>ùóå</mi><mi>ùóà</mi><mi>ùóá</mi></mrow><mrow><mo stretchy="true" form="prefix">[</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œº</mi><mo>+</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow><mo>,</mo><mrow><mrow><mspace width="0.333em"></mspace><mtext mathvariant="normal"> conditionally independent for each </mtext><mspace width="0.333em"></mspace></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi></mrow></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
x_i &amp; \sim \mathsf{Normal}(0,\sigma^2), \text{ independent for each $i=1,\dots,n$,}\\
(y_i|x_i) &amp; \sim \mathsf{Poisson}[\exp(\mu + x_i)], \text{ conditionally independent for each $i=1,\dots,n$}.
\end{aligned}
</annotation></semantics></math></p>
<p>Consider the following simulation code:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">rpois</a></span><span class="op">(</span><span class="fl">30</span>, lambda <span class="op">=</span> <span class="fl">3</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">30</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>What is the expectation of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>?</p>
<ol style="list-style-type: decimal">
<li>
<strong>Theory exercise</strong>: Using the tower property (law of
total variance), theoretically derive an expression for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ùñµ</mi><mi>ùñ∫</mi><mi>ùóã</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathsf{Var}(Y)</annotation></semantics></math>.
You can get the needed log-Normal variance expression from <a href="https://en.wikipedia.org/wiki/Log-normal_distribution" class="external-link">https://en.wikipedia.org/wiki/Log-normal_distribution</a>
</li>
</ol>
<!--

$$
\begin{aligned}
\pVar(Y|\mu,\sigma) &= \pE[\pVar(Y|X)] + \pVar[\pE(Y|X)]
\\&=
\pE[\lambda(\mu,X)] + \pVar[\lambda(\mu,X)]
\\&=
\pE[\exp(\mu+X)] +\pVar[\exp(\mu+X)]
\\&=
\exp(\mu + \sigma^2/2)
+
(\exp(\sigma^2)-1) \exp(2\mu + \sigma^2)
\\&=
\exp(\mu + \sigma^2/2)
\left[
1
+
(\exp(\sigma^2)-1) \exp(\mu + \sigma^2/2)
\right]
\end{aligned}
$$
Since the second factor is always $\geq 1$, this shows that the variance is never smaller than the expectation.
--><ol start="2" style="list-style-type: decimal">
<li>
<strong>Monte Carlo integration</strong>: Use Monte Carlo
integration to approximate the probability mass function
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>p</mi><mi>Y</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="false" form="prefix">|</mo><mi>Œº</mi><mo>,</mo><mi>œÉ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>ùñØ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Y</mi><mo>=</mo><mi>m</mi><mo stretchy="false" form="prefix">|</mo><mi>Œº</mi><mo>,</mo><mi>œÉ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><msubsup><mo>‚à´</mo><mrow><mo>‚àí</mo><mi>‚àû</mi></mrow><mi>‚àû</mi></msubsup><mi>ùñØ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Y</mi><mo>=</mo><mi>m</mi><mo stretchy="false" form="prefix">|</mo><mi>Œº</mi><mo>,</mo><mi>œÉ</mi><mo>,</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>p</mi><mi>X</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>œÉ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi mathvariant="normal">d</mi><mi>x</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
p_Y(m|\mu,\sigma)=\mathsf{P}(Y=m|\mu,\sigma) &amp;= \int_{-\infty}^\infty \mathsf{P}(Y=m|\mu,\sigma,X=x) p_X(x|\sigma) \,\mathrm{d}x
\end{aligned}
</annotation></semantics></math> for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mn>15</mn></mrow><annotation encoding="application/x-tex">m=0,1,2,3,\dots,15</annotation></semantics></math>,
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œº</mi><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\mu=\log(2)-1/2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\sigma=1</annotation></semantics></math>.
Check with the formulas above what the resulting theoretical expectation
is for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
for this parameter combination.</li>
</ol>
<p>For this to be efficient, you should vectorise the calculations by
evaluating the conditional probability function for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
over all the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
values at once, for each simulated value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo>‚àº</mo><mrow><mi>ùñ≠</mi><mi>ùóà</mi><mi>ùóã</mi><mi>ùóÜ</mi><mi>ùñ∫</mi><mi>ùóÖ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><msup><mi>œÉ</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">x^{[k]}\sim\mathsf{Normal}(0,\sigma^2)</annotation></semantics></math>
value, for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">k=1,2,\dots,K</annotation></semantics></math>.
Use
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>10000</mn></mrow><annotation encoding="application/x-tex">K=10000</annotation></semantics></math>
samples.</p>
<p>Plot the resulting probability mass function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>Y</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo stretchy="false" form="prefix">|</mo><mi>Œº</mi><mo>,</mo><mi>œÉ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_Y(m|\mu,\sigma)</annotation></semantics></math>
together with the ordinary Poisson probability mass function with the
same expectation value,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">\lambda = 2</annotation></semantics></math>.
(Use the theory above to convince yourself that these two models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Y</mi><annotation encoding="application/x-tex">Y</annotation></semantics></math>
have the same expectation.)</p>
<!--



In the plot, the overdispersed Poisson probability function (that we just computed) is compared with the plain Poisson probability function for the same expectation value. Lines between values are included for clarity.
Note:
In this case, the second approach is faster, but in other situations the first approach is required, since it doesn't require storing all the random numbers at the same time, thus allowing for a much larger $K=n_{\text{mc}}$ value to be used.
-->
<ol start="3" style="list-style-type: decimal">
<li>
<strong>Reusable function</strong>: Generalise the code to a
function <code>doverpois</code> (for ‚Äúd‚Äùensity for over-dispersed
Poisson) that takes <code>m</code>, <code>mu</code>, <code>sigma</code>,
and <code>K</code> as input and returns a <code>data.frame</code>
suitable for use with <code>ggplot</code>.</li>
</ol>
<!--


--><p>Use the function to plot results for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œº</mi><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>8</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mn>1</mn><mi>/</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">\mu=\log(8)-1/8</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œÉ</mi><mo>=</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">\sigma = 1/2</annotation></semantics></math>,
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mn>30</mn></mrow><annotation encoding="application/x-tex">m=0,1,\dots,30</annotation></semantics></math>
by adding <code>P_Y</code> and <code>P_Poisson</code> geoms to</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu">doverpois</span><span class="op">(</span>m <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">30</span>, mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">8</span><span class="op">)</span> <span class="op">-</span> <span class="fl">0.125</span>, sigma <span class="op">=</span> <span class="fl">0.5</span>, K <span class="op">=</span> <span class="fl">10000</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<!--


-->
</div>
<div class="section level2">
<h2 id="archaeology-in-the-baltic-sea">Archaeology in the Baltic sea<a class="anchor" aria-label="anchor" href="#archaeology-in-the-baltic-sea"></a>
</h2>
<div class="float">
<img src="images%2FWaldemarkreuz_wikipedia.png" alt="The Waldemar cross, source: Wikipedia"><div class="figcaption">The Waldemar cross, source: Wikipedia</div>
</div>
Original inscription, in Latin:
<blockquote>
``Anno Domini MCCCLXI feria III post Jacobi ante portas Visby in manibus
Danorum ceciderunt Gutenses, hic sepulti, orate pro eis!‚Äô‚Äô
</blockquote>
<p><!--
<blockquote>
    "I Herrens {\aa}r 1361, tredje dagen efter S:t Jacob, f\"oll utanf\"or
    Visbys portar gutarna i danskarnas h\"ander. H\"ar \"ar de begravda.
    Bed f\"or dem."
</blockquote>
--></p>
English translation:
<blockquote>
``In the year of our Lord 1361, on the third day after St.¬†Jacob, the
Goth fell outside the gates of Visby at the hands of the Danish. They
are buried here. Pray for them!‚Äô‚Äô
</blockquote>
<p>Strategically located in the middle of the Baltic sea, the island of
Gotland had shifting periods of being partly self-governed, and in
partial control by the Hanseatic trading alliance, Sweden, Denmark, and
the Denmark-Norway-Sweden union, until settling as part of Sweden in
1645. Gotland has an abundance of archaeological treasures, with coins
dating back to Viking era trade routes via Russia to the Arab
Caliphates. and captured the rich Hanseatic town of Visby.</p>
<p>In 1361 the Danish king Valdemar Atterdag conquered Gotland. The
conquest was followed by a plunder of Visby. Most of the defenders
(primarily local farmers that could not take shelter inside the city
walls) were killed in the attack and are buried in a field,
<em>Korsbetningen</em> (Literal translation: <em>the grazing field that
is marked by a cross</em>, as shown in the picture), outside of the
walls of Visby.</p>
<p>In the 1920s the gravesite was subject to several archaeological
excavations. A total of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>493</mn><annotation encoding="application/x-tex">493</annotation></semantics></math>
femurs (thigh bones)
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>256</mn><annotation encoding="application/x-tex">256</annotation></semantics></math>
left, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>237</mn><annotation encoding="application/x-tex">237</annotation></semantics></math>
right) were found. We want to figure out how many persons were likely
buried at the gravesite. It must reasonably have been at least
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>256</mn><annotation encoding="application/x-tex">256</annotation></semantics></math>,
but how many more?</p>
<div class="section level3">
<h3 id="statistical-model">Statistical model<a class="anchor" aria-label="anchor" href="#statistical-model"></a>
</h3>
<p>To build a simple model for this problem, we assume that the number
of left
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>=</mo><mn>256</mn></mrow><annotation encoding="application/x-tex">y_1=256</annotation></semantics></math>)
and right
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>2</mn></msub><mo>=</mo><mn>237</mn></mrow><annotation encoding="application/x-tex">y_2=237</annotation></semantics></math>)
femurs are two independent observations from a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ùñ°</mi><mi>ùóÇ</mi><mi>ùóá</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathsf{Bin}(N,\phi)</annotation></semantics></math>
distribution. Here
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
is the total number of people buried and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
is the probability of finding a femur, left or right, and both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
are unknown parameters.</p>
<p>The probability function for a single observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>‚àº</mo><mrow><mi>ùñ°</mi><mi>ùóÇ</mi><mi>ùóá</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y\sim\mathsf{Bin}(N,\phi)</annotation></semantics></math>
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo stretchy="false" form="prefix">|</mo><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mfrac linethickness="0"><mi>N</mi><mi>y</mi></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>œï</mi><mi>y</mi></msup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>N</mi><mo>‚àí</mo><mi>y</mi></mrow></msup><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*}
p(y|N,\phi) &amp;= {N \choose y} \phi^y (1-\phi)^{N-y} .
\end{align*}</annotation></semantics></math> The function
<code><a href="../reference/arch_loglike.html">arch_loglike()</a></code> in the <code>StatCompLab</code> package
evaluates the combined log-likelihood
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mrow><mo stretchy="true" form="prefix">[</mo><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\log[p(\boldsymbol{y}|N,\phi)]</annotation></semantics></math>
for a collection
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùê≤</mi><annotation encoding="application/x-tex">\boldsymbol{y}</annotation></semantics></math>
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>-observations.
If a <code>data.frame</code> with columns <code>N</code> and
<code>phi</code> is provided, the log-likelihood for each row-pair
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(N,\phi)</annotation></semantics></math>
is returned.</p>
<p>The combined
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>N</mi><mo>,</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>log</mo><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">l(y_1,y_2|N,\theta)=\log p(y_1,y_2|N,\phi)</annotation></semantics></math>
for the data set
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{y_1,y_2\}</annotation></semantics></math>
is then given by
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mi>l</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false" form="prefix">|</mo><mi>N</mi><mo>,</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mo>‚àí</mo><mo>log</mo><mi>Œì</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mo>log</mo><mi>Œì</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>2</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mphantom><mrow><mo>=</mo><mspace width="0.222em"></mspace></mrow></mphantom><mo>‚àí</mo><mo>log</mo><mi>Œì</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>‚àí</mo><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mo>log</mo><mi>Œì</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>‚àí</mo><msub><mi>y</mi><mn>2</mn></msub><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mn>2</mn><mo>log</mo><mi>Œì</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd><mtd columnalign="left" style="text-align: left"><mphantom><mrow><mo>=</mo><mspace width="0.222em"></mspace></mrow></mphantom><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mi>N</mi><mo>‚àí</mo><msub><mi>y</mi><mn>1</mn></msub><mo>‚àí</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
l(y_1,y_2|N,\theta) &amp;= -\log\Gamma(y_1+1) - \log\Gamma(y_2+1)
\\&amp;\phantom{=~}
- \log\Gamma(N-y_1+1) - \log\Gamma(N-y_2+1)
+ 2\log\Gamma(N+1)
\\&amp;\phantom{=~}
 + (y_1+y_2) \log(\phi) + (2 N - y_1 - y_2)\log(1-\phi)
\end{aligned}
</annotation></semantics></math></p>
<p>The task is to use Monte Carlo integration to estimate the posterior
expectations of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>,
when the prior distributions are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>‚àº</mo><mrow><mi>ùñ¶</mi><mi>ùñæ</mi><mi>ùóà</mi><mi>ùóÜ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œæ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N\sim\mathsf{Geom}(\xi)</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>Œæ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0&lt;\xi&lt;1</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>œï</mi><mo>‚àº</mo><mrow><mi>ùñ°</mi><mi>ùñæ</mi><mi>ùóç</mi><mi>ùñ∫</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi\sim\mathsf{Beta}(a, b)</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>,</mo><mi>b</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a,b&gt;0</annotation></semantics></math>.</p>
<p>The mathematical definitions are: Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
have a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ùñ¶</mi><mi>ùñæ</mi><mi>ùóà</mi><mi>ùóÜ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œæ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathsf{Geom}(\xi)</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œæ</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\xi&gt;0</annotation></semantics></math>,
prior distribution, and let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
have a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ùñ°</mi><mi>ùñæ</mi><mi>ùóç</mi><mi>ùñ∫</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathsf{Beta}(a,b)</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>,</mo><mi>b</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">a,b&gt;0</annotation></semantics></math>,
prior distribution:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>p</mi><mi>N</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>ùñØ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>=</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mi>Œæ</mi><mspace width="0.167em"></mspace><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>Œæ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>n</mi></msup><mo>,</mo><mspace width="1.0em"></mspace><mi>n</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>p</mi><mi>œï</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mfrac><mrow><msup><mi>œï</mi><mrow><mi>a</mi><mo>‚àí</mo><mn>1</mn></mrow></msup><msup><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>b</mi><mo>‚àí</mo><mn>1</mn></mrow></msup></mrow><mrow><mi>B</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>,</mo><mspace width="1.0em"></mspace><mi>œï</mi><mo>‚àà</mo><mrow><mo stretchy="true" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">]</mo></mrow><mi>.</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
p_N(n) = \mathsf{P}(N=n) &amp;= \xi\,(1-\xi)^n,\quad n=0,1,2,3,\dots, \\
p_\phi(\phi) &amp;= \frac{\phi^{a-1}(1-\phi)^{b-1}}{B(a,b)}, \quad \phi\in[0,1] .
\end{aligned}
</annotation></semantics></math> and the probability mass function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>N</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_N(n)</annotation></semantics></math>
can be evaluated with <code><a href="https://rdrr.io/r/stats/Geometric.html" class="external-link">dgeom()</a></code> in R, and the density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>œï</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_\phi(\phi)</annotation></semantics></math>
can be evaluated with <code>dbeta</code>.</p>
</div>
<div class="section level3">
<h3 id="bayesian-estimation">Bayesian estimation<a class="anchor" aria-label="anchor" href="#bayesian-estimation"></a>
</h3>
<p>Before the excavation took place, the archaeologist believed that
around
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1000</mn><annotation encoding="application/x-tex">1000</annotation></semantics></math>
individuals were buried, and that they would find around half on the
femurs. To encode that belief in the Bayesian analysis, set
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œæ</mi><mo>=</mo><mn>1</mn><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><mn>1000</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\xi=1/(1+1000)</annotation></semantics></math>,
which corresponds to an expected total count of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1000</mn><annotation encoding="application/x-tex">1000</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mi>b</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">a=b=2</annotation></semantics></math>,
which makes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
more likely to be close to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">1/2</annotation></semantics></math>
than to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>.</p>
<p>The posterior density/probability function for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(N,\phi|\boldsymbol{y})</annotation></semantics></math>
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>p</mi><mrow><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mfrac><mrow><msub><mi>p</mi><mrow><mi>N</mi><mo>,</mo><mi>œï</mi><mo>,</mo><mi>ùê≤</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo>,</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msub><mi>p</mi><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>=</mo><mfrac><mrow><msub><mi>p</mi><mi>N</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>p</mi><mi>œï</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msub><mi>p</mi><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
p_{N,\phi|\boldsymbol{y}}(n,\phi|\boldsymbol{y}) &amp;=
\frac{p_{N,\phi,\boldsymbol{y}}(n,\phi,\boldsymbol{y})}{p_{\boldsymbol{y}}(\boldsymbol{y})}
= \frac{p_N(n)p_\phi(\phi)p(\boldsymbol{y}|n,\phi)}{p_{\boldsymbol{y}}(\boldsymbol{y})}
\end{aligned}
</annotation></semantics></math></p>
<p>We can estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_{\boldsymbol{y}}(\boldsymbol{y})</annotation></semantics></math>
with Monte Carlo integration, the the same time as using importance
sampling to estimate the posterior expectations. The theoretical
expressions
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>p</mi><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>n</mi><mo>=</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="false">‚àû</mo></munderover><msubsup><mo>‚à´</mo><mn>0</mn><mn>1</mn></msubsup><msub><mi>p</mi><mrow><mi>N</mi><mo>,</mo><mi>œï</mi><mo>,</mo><mi>ùê≤</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo>,</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi mathvariant="normal">d</mi><mi>œï</mi><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>n</mi><mo>=</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="false">‚àû</mo></munderover><msubsup><mo>‚à´</mo><mn>0</mn><mn>1</mn></msubsup><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>p</mi><mi>N</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>p</mi><mi>œï</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi mathvariant="normal">d</mi><mi>œï</mi></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mi>ùñ§</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>n</mi><mo>=</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="false">‚àû</mo></munderover><msubsup><mo>‚à´</mo><mn>0</mn><mn>1</mn></msubsup><mi>n</mi><mspace width="0.167em"></mspace><msub><mi>p</mi><mrow><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi mathvariant="normal">d</mi><mi>œï</mi><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>n</mi><mo>=</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="false">‚àû</mo></munderover><msubsup><mo>‚à´</mo><mn>0</mn><mn>1</mn></msubsup><mi>n</mi><mspace width="0.167em"></mspace><mfrac><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msub><mi>p</mi><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><msub><mi>p</mi><mi>N</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>p</mi><mi>œï</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi mathvariant="normal">d</mi><mi>œï</mi></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mi>ùñ§</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>n</mi><mo>=</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="false">‚àû</mo></munderover><msubsup><mo>‚à´</mo><mn>0</mn><mn>1</mn></msubsup><mi>œï</mi><mspace width="0.167em"></mspace><msub><mi>p</mi><mrow><mi>N</mi><mo>,</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi mathvariant="normal">d</mi><mi>œï</mi><mo>=</mo><munderover><mo>‚àë</mo><mrow><mi>n</mi><mo>=</mo><mo>max</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mo accent="false">‚àû</mo></munderover><msubsup><mo>‚à´</mo><mn>0</mn><mn>1</mn></msubsup><mi>œï</mi><mspace width="0.167em"></mspace><mfrac><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>n</mi><mo>,</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msub><mi>p</mi><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><msub><mi>p</mi><mi>N</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>p</mi><mi>œï</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi mathvariant="normal">d</mi><mi>œï</mi></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
p_{\boldsymbol{y}}(\boldsymbol{y}) &amp;=
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1 p_{N,\phi,\boldsymbol{y}}(n,\phi,\boldsymbol{y}) \,\mathrm{d}\phi =
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1 p(\boldsymbol{y}|n,\phi) p_N(n) p_\phi(\phi) \,\mathrm{d}\phi\\
\mathsf{E}(N|\boldsymbol{y}) &amp;=
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1 n\,p_{N,\phi|\boldsymbol{y}}(n,\phi) \,\mathrm{d}\phi =
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1 n\,\frac{p(\boldsymbol{y}|n,\phi)}{p_{\boldsymbol{y}}(\boldsymbol{y})} p_N(n) p_\phi(\phi) \,\mathrm{d}\phi\\
\mathsf{E}(\phi|\boldsymbol{y}) &amp;=
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1 \phi\,p_{N,\phi|\boldsymbol{y}}(n,\phi) \,\mathrm{d}\phi =
\sum_{n=\max(y_1,y_2)}^\infty \int_0^1 \phi\,\frac{p(\boldsymbol{y}|n,\phi)}{p_{\boldsymbol{y}}(\boldsymbol{y})} p_N(n) p_\phi(\phi)
\,\mathrm{d}\phi
\end{aligned}
</annotation></semantics></math></p>
</div>
<div class="section level3">
<h3 id="monte-carlo-integration">Monte Carlo integration<a class="anchor" aria-label="anchor" href="#monte-carlo-integration"></a>
</h3>
<p>What might a good choice of sampling distribution be? In this first
approach to the problem, let‚Äôs use the prior distributions as sampling
distributions for the Monte Carlo integration. This means that we need
to sample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo>‚àº</mo><mrow><mi>ùñ¶</mi><mi>ùñæ</mi><mi>ùóà</mi><mi>ùóÜ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œæ</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">n^{[k]}\sim\mathsf{Geom}(\xi)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>œï</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo>‚àº</mo><mrow><mi>ùñ°</mi><mi>ùñæ</mi><mi>ùóç</mi><mi>ùñ∫</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>,</mo><mi>b</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\phi^{[k]}\sim\mathsf{Beta}(a,b)</annotation></semantics></math>,
and compute Monte Carlo estimates
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mover><mi>p</mi><mo accent="true">ÃÇ</mo></mover><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mfrac><mn>1</mn><mi>K</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><msup><mi>n</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo>,</mo><msup><mi>œï</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mover><mi>ùñ§</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mfrac><mn>1</mn><mrow><mi>K</mi><msub><mover><mi>p</mi><mo accent="true">ÃÇ</mo></mover><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><munderover><mo>‚àë</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msup><mi>n</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><msup><mi>n</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo>,</mo><msup><mi>œï</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mover><mi>ùñ§</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mtd><mtd columnalign="left" style="text-align: left"><mo>=</mo><mfrac><mn>1</mn><mrow><mi>K</mi><msub><mover><mi>p</mi><mo accent="true">ÃÇ</mo></mover><mi>ùê≤</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><munderover><mo>‚àë</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msup><mi>œï</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><msup><mi>n</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo>,</mo><msup><mi>œï</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\widehat{p}_{\boldsymbol{y}}(\boldsymbol{y}) &amp;=
\frac{1}{K}
  \sum_{k=1}^K p(\boldsymbol{y}|n^{[k]},\phi^{[k]})\\
\widehat{\mathsf{E}}(N|\boldsymbol{y}) &amp;=
  \frac{1}{K \widehat{p}_{\boldsymbol{y}}(\boldsymbol{y})}
  \sum_{k=1}^K n^{[k]} p(\boldsymbol{y}|n^{[k]},\phi^{[k]})\\
\widehat{\mathsf{E}}(\phi|\boldsymbol{y}) &amp;=
  \frac{1}{K \widehat{p}_{\boldsymbol{y}}(\boldsymbol{y})}
  \sum_{k=1}^K \phi^{[k]} p(\boldsymbol{y}|n^{[k]},\phi^{[k]})\\
\end{aligned}
</annotation></semantics></math> Write a function <code>estimate</code>
that takes inputs <code>y</code>, <code>xi</code>, <code>a</code>,
<code>b</code>, and <code>K</code> and implements the above Monte Carlo
integration method.</p>
<p>Test the function by running
<code>estimate(y=c(237,256), xi=1/1001, a=0.5, b=0.5, K=10000)</code></p>
<!--



-->
<p>Note: as shown in lecture 3, the conditional posterior distribution
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>œï</mi><annotation encoding="application/x-tex">\phi</annotation></semantics></math>
for fixed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">N=n</annotation></semantics></math>
is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>œï</mi><mo stretchy="false" form="prefix">|</mo><mi>n</mi><mo>,</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àº</mo><mrow><mi>ùñ°</mi><mi>ùñæ</mi><mi>ùóç</mi><mi>ùñ∫</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>+</mo><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mi>b</mi><mo>+</mo><mn>2</mn><mi>n</mi><mo>‚àí</mo><msub><mi>y</mi><mn>1</mn></msub><mo>‚àí</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(\phi|n,\boldsymbol{y})\sim \mathsf{Beta}(a+y_1+y_2,b+2n-y_1-y_2)</annotation></semantics></math>.
This can be used to construct a potentially more efficient method, where
each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>œï</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><annotation encoding="application/x-tex">\phi^{[k]}</annotation></semantics></math>
is sampled conditionally on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>n</mi><mrow><mo stretchy="true" form="prefix">[</mo><mi>k</mi><mo stretchy="true" form="postfix">]</mo></mrow></msup><annotation encoding="application/x-tex">n^{[k]}</annotation></semantics></math>,
and the integration importance weights adjusted appropriately.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Finn Lindgren.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
