<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Tutorial 04: Uncertainty and integration (solutions) ‚Ä¢ StatCompLab</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Tutorial 04: Uncertainty and integration (solutions)">
<meta name="description" content="Statistical Computing: Lab tutorial 4">
<meta property="og:description" content="Statistical Computing: Lab tutorial 4">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">StatCompLab</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">25.4.9</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/Project_Example_Solution.html">StatComp Project Example Solution: Numerical Statistics</a></li>
    <li><a class="dropdown-item" href="../articles/Project_Example.html">StatComp Project Example: Numerical statistics</a></li>
    <li><a class="dropdown-item" href="../articles/Project01.html">StatComp Project 1 (2022/23): Simulation and sampling</a></li>
    <li><a class="dropdown-item" href="../articles/Project01Hints.html">StatComp Project 1 (2022/23): Hints</a></li>
    <li><a class="dropdown-item" href="../articles/Project02.html">StatComp Project 2: Scottish weather</a></li>
    <li><a class="dropdown-item" href="../articles/Project02Hints.html">StatComp Project 2 (2022/23): Hints</a></li>
    <li><a class="dropdown-item" href="../articles/Quiz1Solution.html">Quiz 1 Solution (StatComp 2021/22)</a></li>
    <li><a class="dropdown-item" href="../articles/T4sol.html">Tutorial 04: Uncertainty and integration (full solution)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial01.html">Tutorial 01: R and linear models</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial01Solutions.html">Tutorial 01: R and linear models (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial02.html">Tutorial 02: Optimization</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial02Solutions.html">Tutorial 02: Optimization (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial03.html">Tutorial 03: Monte Carlo integration</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial03Solutions.html">Tutorial 03: Monte Carlo integration (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial04.html">Tutorial 04: Uncertainty and integration</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial04Solutions.html">Tutorial 04: Uncertainty and integration (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial06.html">Tutorial 06: Prediction assessment with proper scores</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial06Solutions.html">Tutorial 06: Prediction assessment with proper scores (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial07.html">Tutorial 07: Data wrangling and cross validation</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial07Solutions.html">Tutorial 07: Data wrangling and cross validation (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial08.html">Tutorial 08: Floating point computations and least squares</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial08Solutions.html">Tutorial 08: Floating point computations and least squares (solutions)</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial09.html">Tutorial 09: Bootstrap and Pareto smoothed importance sampling</a></li>
    <li><a class="dropdown-item" href="../articles/Tutorial09Solutions.html">Tutorial 09: Bootstrap and Pareto smoothed importance sampling (solutions)</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/finnlindgren/StatCompLab/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Tutorial 04: Uncertainty and integration (solutions)</h1>
                        <h4 data-toc-skip class="author">Finn
Lindgren</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/finnlindgren/StatCompLab/blob/main/vignettes/Tutorial04Solutions.Rmd" class="external-link"><code>vignettes/Tutorial04Solutions.Rmd</code></a></small>
      <div class="d-none name"><code>Tutorial04Solutions.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>In this lab session you will explore</p>
<ul>
<li>using RMarkdown to organise text and code</li>
<li>maximum likelihood estimator sampling distributions and approximate
confidence interval construction</li>
<li>Laplace approximation and importance sampling for approximate
Bayesian credible interval construction</li>
</ul>
<ol style="list-style-type: decimal">
<li>Clone your <code>lab04-*</code> repository from <a href="https://github.com/StatComp21/" class="external-link">https://github.com/StatComp21/</a>
either on your own computer (new Project from version control) or to <a href="https://rstudio.cloud" class="external-link">https://rstudio.cloud</a>
</li>
<li>If on rstudio.cloud, setup <code>GITHUB_PAT</code> credentials, like
before.</li>
<li>Upgrade/install the <code>StatCompLab</code> package, see <a href="https://finnlindgren.github.io/StatCompLab/">https://finnlindgren.github.io/StatCompLab/</a>
</li>
<li>The repository has two files, <code>RMDemo.Rmd</code> and
<code>my_code.R</code>. Make a copy of <code>RMDemo.Rmd</code>, and call
it <code>Lab4.Rmd</code>
</li>
<li>During this lab, modify the <code>Lab4.Rmd</code> document and add
new code and text commentary for the lab to the document. (You can
remove the demonstration parts of the file when you don‚Äôt need them
anymore, and/or keep a separate copy of it.) When pressing the ‚Äúknit‚Äù
button, the RMarkdown file will be run in its own R environment, so you
need to include any needed <code><a href="https://rdrr.io/r/base/library.html" class="external-link">library()</a></code> calls in a code chnk
in the file, normally an initial ‚Äúsetup‚Äù chunk.</li>
</ol>
<!--

The accompanying `Tutorial04Solutions` tutorial/vignette documents contain the
solutions explicitly, to make it easier to review the material after the workshops.
The separate `T4sol.Rmd` document at [https://github.com/finnlindgren/StatCompLab/blob/main/vignettes/articles/T4sol.Rmd](https://github.com/finnlindgren/StatCompLab/blob/main/vignettes/articles/T4sol.Rmd) is the source document for the standalone solution shown in `T4sol` on the `StatCompLab` website.  
-->
</div>
<div class="section level2">
<h2 id="three-alternatives-for-poisson-parameter-confidence-intervals">Three alternatives for Poisson parameter confidence intervals<a class="anchor" aria-label="anchor" href="#three-alternatives-for-poisson-parameter-confidence-intervals"></a>
</h2>
<p>Consider the Poisson model for observations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùê≤</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>y</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\boldsymbol{y}=\{y_1,\dots,y_n\}</annotation></semantics></math>:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><msub><mi>y</mi><mi>i</mi></msub></mtd><mtd columnalign="left" style="text-align: left"><mo>‚àº</mo><mrow><mi>ùñØ</mi><mi>ùóà</mi><mi>ùóÇ</mi><mi>ùóå</mi><mi>ùóå</mi><mi>ùóà</mi><mi>ùóá</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mspace width="1.0em"></mspace><mrow><mrow><mtext mathvariant="normal">independent for </mtext><mspace width="0.333em"></mspace></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>n</mi></mrow><mtext mathvariant="normal">.</mtext></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
y_i &amp; \sim \mathsf{Poisson}(\lambda), \quad\text{independent for $i=1,\dots,n$.}
\end{aligned}
</annotation></semantics></math> that has joint probability mass
function
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><mi>n</mi><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><munderover><mo>‚àè</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfrac><msup><mi>Œª</mi><msub><mi>y</mi><mi>i</mi></msub></msup><mrow><msub><mi>y</mi><mi>i</mi></msub><mi>!</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">
p(\boldsymbol{y}|\lambda) = \exp(-n\lambda) \prod_{i=1}^n \frac{\lambda^{y_i}}{y_i!}
</annotation></semantics></math> In the week 4 lecture, two
parameterisations were considered. We now add a third option:</p>
<ol style="list-style-type: decimal">
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi><mo>=</mo><mi>Œª</mi></mrow><annotation encoding="application/x-tex">\theta = \lambda</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mtext mathvariant="normal">ML</mtext></msub><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover></mrow><annotation encoding="application/x-tex">\widehat{\theta}_\text{ML}=\frac{1}{n}\sum_{i=1}^n y_i = \overline{y}</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi><mo>=</mo><msqrt><mi>Œª</mi></msqrt></mrow><annotation encoding="application/x-tex">\theta = \sqrt{\lambda}</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mtext mathvariant="normal">ML</mtext></msub><mo>=</mo><msqrt><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover></msqrt></mrow><annotation encoding="application/x-tex">\widehat{\theta}_\text{ML}=\sqrt{\overline{y}}</annotation></semantics></math>
</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta = \log(\lambda)</annotation></semantics></math>,
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mtext mathvariant="normal">ML</mtext></msub><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widehat{\theta}_\text{ML}=\log\left(\overline{y}\right)</annotation></semantics></math>
</li>
</ol>
<p>From the week 4 lecture, we know that the inverse expected Fisher
information is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mi>/</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">\lambda/n</annotation></semantics></math>
for case 1 and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>4</mn><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">1/(4n)</annotation></semantics></math>
for case 2. For case 3, show that the inverse expected Fisher
information is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">1/(n\lambda)</annotation></semantics></math>.</p>
<hr>
<p><strong>Solution:</strong></p>
<p>For case 3, the negated log-likelihood is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>l</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>n</mi><msup><mi>e</mi><mi>Œ∏</mi></msup><mo>‚àí</mo><mi>Œ∏</mi><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mtext mathvariant="normal">constant</mtext></mrow><annotation encoding="application/x-tex">
\widetilde{l}(\theta) = n e^\theta - \theta \sum_{i=1}^n y_i + \text{constant}
</annotation></semantics></math> with 1st order derivative
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>‚àÇ</mi><mrow><mi>‚àÇ</mi><mi>Œ∏</mi></mrow></mfrac><mover><mi>l</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>n</mi><msup><mi>e</mi><mi>Œ∏</mi></msup><mo>‚àí</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
\frac{\partial}{\partial\theta}\widetilde{l}(\theta) = n e^\theta - \sum_{i=1}^n y_i
</annotation></semantics></math> which shows that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>Œ∏</mi><mo accent="true">ÃÇ</mo></mover><mtext mathvariant="normal">ML</mtext></msub><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widehat{\theta}_\text{ML}=\log(\overline{y})</annotation></semantics></math>,
and 2nd order derivative
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><msup><mi>‚àÇ</mi><mn>2</mn></msup><mrow><mi>‚àÇ</mi><msup><mi>Œ∏</mi><mn>2</mn></msup></mrow></mfrac><mover><mi>l</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>n</mi><msup><mi>e</mi><mi>Œ∏</mi></msup></mrow><annotation encoding="application/x-tex">
\frac{\partial^2}{\partial\theta^2}\widetilde{l}(\theta) = n e^\theta
</annotation></semantics></math> which is equal to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>Œª</mi></mrow><annotation encoding="application/x-tex">n\lambda</annotation></semantics></math>
for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
values, so the inverse of the expected Hessian is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">1/(n\lambda)</annotation></semantics></math>.</p>
<hr>
<div class="section level3">
<h3 id="interval-construction">Interval construction<a class="anchor" aria-label="anchor" href="#interval-construction"></a>
</h3>
<p>Use the approximation method for large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
from the lecture to construct approximate confidence intervals for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
using each of the three parameterisations. Define three functions, CI1,
CI2, and CI3, each taking paramters</p>
<ul>
<li>
<code>y</code>: a vector of observed values</li>
<li>
<code>alpha</code>: the nominal error probability of the confidence
intervals</li>
</ul>
<p>To avoid having to specify <code>alpha</code> in a common case, you
can use <code>alpha = 0.05</code> in the function argument definition to
set a default value.</p>
<p>The function <code>pmax</code> may be useful (see its help text).</p>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">CI1</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">alpha</span> <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span>  <span class="va">lambda_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span>  <span class="va">theta_interval</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">lambda_hat</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">lambda_hat</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmax</a></span><span class="op">(</span><span class="va">theta_interval</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="va">CI2</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">alpha</span> <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span>  <span class="va">theta_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">theta_interval</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">theta_hat</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fl">4</span> <span class="op">*</span> <span class="va">n</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmax</a></span><span class="op">(</span><span class="va">theta_interval</span>, <span class="fl">0</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="op">}</span></span>
<span><span class="va">CI3</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">y</span>, <span class="va">alpha</span> <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span>  <span class="va">theta_hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">theta_interval</span> <span class="op">&lt;-</span></span>
<span>    <span class="va">theta_hat</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">theta_hat</span><span class="op">)</span> <span class="op">*</span> <span class="va">n</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">qnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span>, <span class="va">alpha</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">theta_interval</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<hr>
<p>You can use the following code to test your functions, storing each
interval as a row of a matrix with <code>rbind</code> (‚Äúbind‚Äù as ‚Äúrows‚Äù,
see also <code>cbind</code> for combining columns):</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">rpois</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5</span>, lambda <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0 2 2 2 4</span></span></code></pre>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">CI</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="st">"Method 1"</span> <span class="op">=</span> <span class="fu">CI1</span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,</span>
<span>  <span class="st">"Method 2"</span> <span class="op">=</span> <span class="fu">CI2</span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,</span>
<span>  <span class="st">"Method 3"</span> <span class="op">=</span> <span class="fu">CI3</span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">CI</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Lower"</span>, <span class="st">"Upper"</span><span class="op">)</span></span></code></pre></div>
<p>We can print the result as a table in our RMarkdown by using a
separate codechunk, calling the <code><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">knitr::kable</a></code> function:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">CI</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<thead><tr class="header">
<th align="left"></th>
<th align="right">Lower</th>
<th align="right">Upper</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Method 1</td>
<td align="right">0.7604099</td>
<td align="right">3.239590</td>
</tr>
<tr class="even">
<td align="left">Method 2</td>
<td align="right">0.9524829</td>
<td align="right">3.431663</td>
</tr>
<tr class="odd">
<td align="left">Method 3</td>
<td align="right">1.0761094</td>
<td align="right">3.717094</td>
</tr>
</tbody>
</table>
<p>Will all three methods always produce a valid interval? Consider the
possible values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover><annotation encoding="application/x-tex">\overline{y}</annotation></semantics></math>.
Experiment with different values of <code>n</code> and
<code>lambda</code> in the simulation of <code>y</code>.</p>
<hr>
<p><strong>Solution:</strong></p>
<p>When
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\overline{y}=0</annotation></semantics></math>,
the first method produces a single point as ‚Äúinterval‚Äù.</p>
<p>The third method fails if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\overline{y}=0</annotation></semantics></math>,
due to log of zero.</p>
<p>This can happen when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
are close to zero.</p>
<hr>
<p>For each approximate confidence interval construction method, we
might ask the question of whether it fulfils the definition of an actual
confidence interval construction method; that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ùñØ</mi><mrow><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>Œ∏</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo>‚àà</mo><mtext mathvariant="normal">CI</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="false" form="prefix">|</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚â•</mo><mn>1</mn><mo>‚àí</mo><mi>Œ±</mi></mrow><annotation encoding="application/x-tex">\mathsf{P}_{\boldsymbol{y}|\theta}(\theta\in \text{CI}(\boldsymbol{y})|\theta)\geq 1-\alpha</annotation></semantics></math>
for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
(or at least for a relevant subset of the parameter space). In
coursework project 1, you will investigate the accuracy of some
approximate confidence interval construction methods.</p>
</div>
</div>
<div class="section level2">
<h2 id="bayesian-credible-intervals">Bayesian credible intervals<a class="anchor" aria-label="anchor" href="#bayesian-credible-intervals"></a>
</h2>
<p>Assume a true value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">\lambda=10</annotation></semantics></math>,
and simulate a sample of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùê≤</mi><annotation encoding="application/x-tex">\boldsymbol{y}</annotation></semantics></math>
of size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">n=5</annotation></semantics></math>.</p>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">5</span></span>
<span><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">rpois</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">lambda</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="co"># Actual values will depend on if set.seed() was used at the beginning of the document</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 11  7 11  8  8</span></span></code></pre>
<hr>
<p>Now consider a Bayesian version of the Poisson model, with prior
model
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mo>‚àº</mo><mrow><mi>ùñ§</mi><mi>ùóë</mi><mi>ùóâ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\lambda \sim \mathsf{Exp}(a)
</annotation></semantics></math> that has probability density function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>a</mi><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><mi>a</mi><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\lambda) = a \exp(-a \lambda)</annotation></semantics></math>.</p>
<p>One can show that the exact posterior distribution for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùê≤</mi><annotation encoding="application/x-tex">\boldsymbol{y}</annotation></semantics></math>
is a
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi>ùñ¶</mi><mi>ùñ∫</mi><mi>ùóÜ</mi><mi>ùóÜ</mi><mi>ùñ∫</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><mi>a</mi><mo>+</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathsf{Gamma}(1 + \sum_{i=1}^n y_i, a + n)</annotation></semantics></math>
distribution (using the shape&amp;rate parameterisation), and credible
intervals can be constructed from quantiles of this distribution.</p>
<p>In cases where the theoretical construction is impractical, an
alternative is to instead construct samples from the posterior
distribution, and extract empirical quantiles from this sample. Here, we
will use importance sampling to achieve this.</p>
<p>Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œ∏</mi><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\theta=\log(\lambda)</annotation></semantics></math>,
so that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Œª</mi><mo>=</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\lambda=\exp(\theta)</annotation></semantics></math>.
Show that the prior probability density for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>a</mi><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo>‚àí</mo><mi>a</mi><msup><mi>e</mi><mi>Œ∏</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\theta)=a \exp\left( \theta-ae^\theta \right)</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="gaussian-approximation">Gaussian approximation<a class="anchor" aria-label="anchor" href="#gaussian-approximation"></a>
</h3>
<hr>
<p><strong>Solution:</strong></p>
<p><em>Alternative 1</em>: From probability theory, we know that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><mfrac><mrow><mi>d</mi><mi>Œª</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>d</mi><mi>Œ∏</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">p(\theta)=p(\lambda) \frac{d\lambda(\theta)}{d\theta}</annotation></semantics></math>,
so that
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>a</mi><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><mi>a</mi><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>a</mi><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo>‚àí</mo><mi>a</mi><msup><mi>e</mi><mi>Œ∏</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
p(\theta) = a \exp(-a\lambda) \exp(\theta) = a \exp\left( \theta-ae^\theta \right)
</annotation></semantics></math></p>
<p><em>Alternative 2</em>: First, we derive the CDF:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùñØ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo>‚â§</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>ùñØ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚â§</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>ùñØ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo>‚â§</mo><msup><mi>e</mi><mi>x</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>1</mn><mo>‚àí</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><mi>a</mi><msup><mi>e</mi><mi>x</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathsf{P}(\theta \leq x)=\mathsf{P}(\log(\lambda) \leq x)=\mathsf{P}(\lambda \leq e^x) = 1 - \exp(-a e^x)</annotation></semantics></math>,
from the CDF for the Exponential distribution. Taking the derivative
with respect to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
gives the density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>Œ∏</mi></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>‚àí</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><mi>a</mi><msup><mi>e</mi><mi>x</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow><mfrac><mi>d</mi><mrow><mi>d</mi><mi>x</mi></mrow></mfrac><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><mi>a</mi><msup><mi>e</mi><mi>x</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>‚àí</mo><mi>a</mi><msup><mi>e</mi><mi>x</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><msup><mi>e</mi><mi>x</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>a</mi><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo>‚àí</mo><mi>a</mi><msup><mi>e</mi><mi>x</mi></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_\theta(x)=-\exp(-a e^x) \frac{d}{dx} (-a e^x) = \exp(-a e^x) (a e^x) = a \exp(x - a e^x)</annotation></semantics></math>,
which is the needed result.</p>
<hr>
<p>The posterior density function for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
is
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">
p(\theta|\boldsymbol{y}) = \frac{p(\theta) p(\boldsymbol{y}|\theta)}{p(\boldsymbol{y})}
</annotation></semantics></math> with log-density
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mtext mathvariant="normal">const</mtext><mo>+</mo><mi>Œ∏</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>+</mo><mi>n</mi><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>a</mi><mo>+</mo><mi>n</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
\log p(\theta|\boldsymbol{y}) = \text{const} + \theta (1 + n\overline{y}) - (a+n)\exp(\theta) ,
</annotation></semantics></math> and by taking derivatives we find the
mode at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>Œ∏</mi><mo accent="true">ÃÉ</mo></mover><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mfrac><mrow><mn>1</mn><mo>+</mo><mi>n</mi><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover></mrow><mrow><mi>a</mi><mo>+</mo><mi>n</mi></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widetilde{\theta}=\log\left(\frac{1+n\overline{y}}{a+n}\right)</annotation></semantics></math>,
and negated Hessian
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>+</mo><mi>n</mi><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover></mrow><annotation encoding="application/x-tex">1+n\overline{y}</annotation></semantics></math>
at the mode.</p>
<p>With this information we can construct a Gaussian approximation to
the posterior distribution,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>p</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àº</mo><mrow><mi>ùñ≠</mi><mi>ùóà</mi><mi>ùóã</mi><mi>ùóÜ</mi><mi>ùñ∫</mi><mi>ùóÖ</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>Œ∏</mi><mo accent="true">ÃÉ</mo></mover><mo>,</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>n</mi><mover><mi>y</mi><mo accent="true">¬Ø</mo></mover></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widetilde{p}(\theta|\boldsymbol{y})\sim\mathsf{Normal}(\widetilde{\theta},\frac{1}{1+n\overline{y}})</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="importance-sampling">Importance sampling<a class="anchor" aria-label="anchor" href="#importance-sampling"></a>
</h3>
<p>Simulate a sample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ùê±</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>x</mi><mi>m</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\boldsymbol{x}=\{x_1,\dots,x_m\}</annotation></semantics></math>
from this Gaussian approximation of the posterior distribution, for some
large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>&gt;</mo><mn>10000</mn></mrow><annotation encoding="application/x-tex">m &gt; 10000</annotation></semantics></math>,
with hyperparameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>1</mn><mi>/</mi><mn>5</mn></mrow><annotation encoding="application/x-tex">a=1/5</annotation></semantics></math>.</p>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">a</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">/</span><span class="fl">5</span></span>
<span><span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">20000</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">m</span>, mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span><span class="op">+</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">a</span> <span class="op">+</span> <span class="va">n</span><span class="op">)</span>, sd <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<hr>
<p>We need to calculate unnormalised <em>importance weights</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>k</mi></msub><annotation encoding="application/x-tex">w_k</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">k=1,\dots,m</annotation></semantics></math>,
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub><mo>=</mo><msub><mrow><mfrac><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo stretchy="false" form="prefix">|</mo><mi>Œ∏</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mover><mi>p</mi><mo accent="true">ÃÉ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œ∏</mi><mo stretchy="false" form="prefix">|</mo><mi>ùê≤</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo stretchy="true" form="postfix">|</mo></mrow><mrow><mi>Œ∏</mi><mo>=</mo><msub><mi>x</mi><mi>k</mi></msub></mrow></msub><mi>.</mi></mrow><annotation encoding="application/x-tex">
w_k = \left.\frac{p(\theta)p(\boldsymbol{y}|\theta)}{\widetilde{p}(\theta|\boldsymbol{y})}\right|_{\theta=x_k} .
</annotation></semantics></math> Due to lack of normalisation, these
‚Äúraw‚Äù weights cannot be represented accurately in the computer. To get
around that issue, first compute the logarithm of the weights,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>w</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\log(w_k)</annotation></semantics></math>,
and then new, equivalent unnormalised weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>w</mi><mo accent="true">ÃÉ</mo></mover><mi>k</mi></msub><mo>=</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">[</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>w</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>‚àí</mo><msub><mo>max</mo><mi>j</mi></msub><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>w</mi><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\widetilde{w}_k=\exp[\log(w_k) - \max_j \log(w_j)]</annotation></semantics></math>.</p>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">log_weights</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">x</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="op">(</span><span class="va">a</span> <span class="op">+</span> <span class="va">n</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span></span>
<span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="va">x</span>, mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">a</span> <span class="op">+</span> <span class="va">n</span><span class="op">)</span>, sd <span class="op">=</span> <span class="fl">1</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span>, log <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">weights</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">log_weights</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">log_weights</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<hr>
<p>Look at the help text for the function <code>wquantile</code> (in the
StatCompLab package, from version 0.4.0) that computes quantiles from a
weighted sample, and construct a 95% credible interval for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ∏</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
using the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùê±</mi><annotation encoding="application/x-tex">\boldsymbol{x}</annotation></semantics></math>
sample and associate weights, and then transform it into a credible
interval for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></p>
<hr>
<p><strong>Solution:</strong></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">theta_interval</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/wquantile.html">wquantile</a></span><span class="op">(</span><span class="va">x</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span>, weights <span class="op">=</span> <span class="va">weights</span><span class="op">)</span></span>
<span><span class="va">theta_interval</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.873696 2.448506</span></span></code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lambda_interval</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">theta_interval</span><span class="op">)</span></span>
<span><span class="va">lambda_interval</span></span></code></pre></div>
<pre><code><span><span class="co">## [1]  6.512323 11.571043</span></span></code></pre>
<hr>
</div>
<div class="section level3">
<h3 id="cumulative-distribution-function-comparison">Cumulative distribution function comparison<a class="anchor" aria-label="anchor" href="#cumulative-distribution-function-comparison"></a>
</h3>
<p>With <code>ggplot</code>, use <code>geom_function</code> to plot the
theoretical posterior cumulative distribution function for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
(the CDF from the Gamma distribution given above, see
<code><a href="https://rdrr.io/r/stats/GammaDist.html" class="external-link">pgamma()</a></code>) and compare it to the approximation given by the
importance sampling. The <code><a href="../reference/stat_ewcdf.html">stat_ewcdf()</a></code> function from the
StatCompLab should be used to plot the cdf for the weighted sample
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Œª</mi><mi>k</mi></msub><mo>=</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\lambda_k=\exp(x_k)</annotation></semantics></math>,
with (unnormalised) weights
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>w</mi><mi>k</mi></msub><annotation encoding="application/x-tex">w_k</annotation></semantics></math>.
Also include the unweighted sample, with <code>stat_ecwf()</code>. How
close does the approximations come to the true posterior
distribution?</p>
<hr>
<p><strong>Solution:</strong></p>
<p>The importance sampling version is virtually indistinguishable from
the true posterior distribution. The unweighted sample is very close to
the true posterior distribution; for this model, the Gaussian
approximation of the posterior distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>Œª</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\log(\lambda)</annotation></semantics></math>
is an excellent approximation even before we add the importance sampling
step.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>lambda <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, weights <span class="op">=</span> <span class="va">weights</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">xlim</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">20</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">ylab</a></span><span class="op">(</span><span class="st">"CDF"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_function.html" class="external-link">geom_function</a></span><span class="op">(</span>fun <span class="op">=</span> <span class="va">pgamma</span>, args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, rate <span class="op">=</span> <span class="va">a</span> <span class="op">+</span> <span class="va">n</span><span class="op">)</span>,</span>
<span>                mapping <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>col <span class="op">=</span> <span class="st">"Theory"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="../reference/stat_ewcdf.html">stat_ewcdf</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">lambda</span>, weights <span class="op">=</span> <span class="va">weights</span>, col <span class="op">=</span> <span class="st">"Importance"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/stat_ecdf.html" class="external-link">stat_ecdf</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span><span class="va">lambda</span>, col <span class="op">=</span> <span class="st">"Unweighted"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Warning in geom_function(fun = pgamma, args = list(shape = 1 + sum(y), rate = a + : All aesthetics have length 1, but the data has 20000 rows.</span></span>
<span><span class="co">## <span style="color: #00BBBB;">‚Ñπ</span> Please consider using `annotate()` or provide this layer with data containing</span></span>
<span><span class="co">##   a single row.</span></span></code></pre>
<p><img src="Tutorial04Solutions_files/figure-html/ecdf-show-1.png" width="576"></p>
<hr>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Finn Lindgren.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
